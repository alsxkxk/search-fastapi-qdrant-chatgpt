Content
"계층 구조에서 보는 운영체제의 기능, 사용자가 하드웨어에 대해 몰라도 컴퓨터를 사용할 수 있도록 함, 응용프로그램과 하드웨어 사이의 중계"
"CPU(Central Processing Unit)
프로그램 코드, 기계 명령을 해석하여 실행하는 중앙처리장치
컴퓨터의 가장 핵심 장치
전원이 공급될 때 작동 시작, 메모리에 적재된 프로그램 실행"
"메모리
CPU에 의해 실행되는 프로그램 코드와 데이터가 적재되는 공간
반도체 메모리 RAM
프로그램은 실행되기 위해 반드시 메모리에 적재되어야 함"
"캐시 메모리(Cache Memory)
CPU 처리속도가 메모리 속도에 비해 빠르게 향상-> CPU는 느린 메모리 때문에
대기시간 늘게 되었음
CPU의 프로그램 실행 속도는 높이기 위해, CPU와 메모리 사이에 설치되는 소량의
빠른 메모리, 고가의 메모리
온칩 캐시(on-chip) – CPU 내부에 설치되는 캐시
옵칩 캐시(off-chip) – CPU 외부에 설치되는 캐시
캐시 메모리가 있는 경우 CPU는 캐시 메모리에서 프로그램 실행"
"프로그램이 실행되기 위해 운영체제에 의해 할당되는 4 공간
코드(code) 공간 – 프로그램 코드 적재
데이터(data) 공간- 전역 변수들이 적재되는 공간
힙(heap) 공간 – 프로그램 동적으로 저장할 데이터를 위한 공간
스택(stack) 공간 – 함수가 호출될 때 매개변수, 지역변수 등 저장"
"스택
스택이라는 별도의 하드웨어 메모리가 있는 것 아님
메모리의 일부를 스택으로 사용하도록 할당된 공간
각 프로그램에게 자신만의 스택 공간 할당
CPU의 SP 레지스터가 현재 프로그램의 스택 꼭대기 주소를 가리킴"
"컨텍스트 스위칭
정의
현재 실행중인 프로그램의 컨텍스트(CPU레지스터들의 값)를 저장
다른 프로그램의 저장된 컨텍스트 (CPU레지스터들의 값)를 CPU에 복귀
발생
CPU가 현재 프로그램 실행을 중지하고 다른 프로그램을 실행할 때"
"운영체제가 없다면
응용프로그램이나 사용자가 직접 하드웨어를 제어해야 함
하드웨어에 대한 지식, 충돌, 관리, 보안의 문제 발생"
"응용프로그램에 대한 운영체제의 역할
응용프로그램이 직접 하드웨어를 다루지 못하도록 차단
운영체제가 하드웨어 완벽히 독점 장악
이유 : 응용프로그램들 사이의 하드웨어 사용 충돌을 막기 위함
응용프로그램은 하드웨어를 사용하고자 할 때
반드시 운영체제에게 요청-> 운영체제가 대신하여 하드웨어 조작
유일한 요청 방법 – 시스템 호출(system call)
응용프로그램과 하드웨어 사이의 인터페이스
응용프로그램들의 실행 순서 제어
응용프로그램들 사이의 통신 중계"
"사용자에 대한 운영체제의 역할
사용자가 하드웨어에 관한 지식이 없어도 컴퓨터 다루기 용이
사용자가 하드웨어를 설치하거나 변경하는 것에 도움
사용자에게 컴퓨터 시스템을 사용할 편리한 인터페이스 제공
UI, 마우스, 음성 명령 등
컴퓨터의 사용을 돕는 여러 도구 응용프로그램(유틸리티) 제공
Windows의 탐색기와 작업 관리자
리눅스의 쉘
사용자 계정 관리
사용자의 컴퓨터 사용 시간 계산, 과금 처리 등"
"운영체제의 전체 기능
프로세스와 스레드 관리
프로세스/스레드의 실행, 일시 중단, 종료, 스케줄링, 컨텍스트 스위칭, 동기화
메모리 관리
프로세스나 스레드에게 메모리 할당, 메모리 반환, 다른 프로세스/스레드로부터의 메모리 보호
메모리를 하드 디스크의 영역까지 확장하는 가상 메모리 기술
파일 관리 혹은 파일 시스템 관리
파일 생성, 저장, 읽기, 복사, 삭제, 이동, 파일 보호
장치 관리
키보드, 마우스, 프린터 등 입출력 장치, 하드 디스크 등 저장 장치 제어
입출력
사용자 인터페이스
라인 기반 명령 입출력 창, 마우스와 그래픽 사용 GUI 인터페이스
네트워킹
네트워크 인지, 연결, 닫기, 데이터 송수신
보호 및 보안
바이러스나 웜, 멀웨어(malware), 해킹 등의 외부 공격이나 무단 침입으로부터 보호"
운영체제 = 커널 + 툴 + 디바이스 드라이버
"커널(kernel)
운영체제의 핵심 부분, 좁은 의미의 운영체제
부팅 후 메모리에 상주하는 코드와 데이터
커널 코드는 함수들의 집합의 구성
커널 기능을 이용하려면 응용프로그램은 반드시 시스템 호출을 사용"
커널이 제공하는 2개 인터페이스 : 시스템 호출과 인터럽트
"시스템 호출(system call)
커널과 응용프로그램 사이의 인터페이스
응용프로그램에서 커널 기능을 사용할 수 있는 유일한 방법"
"인터럽트(interrupt)
커널과 하드웨어 장치 사이의 인터페이스
장치들이 입출력 완료, 타이머 완료 등을 CPU에게 알리는 하드웨어적 방법"
"운영체제는 컴퓨터 메모리를 두 공간으로 분리
사용자 공간(user space) : 모든 응용프로그램들이 나누어 사용하는 공간
커널 공간(kernel space) : 커널만 사용할 수 있는 공간"
CPU는 사용자 모드와 커널 모드 중 한 모드로 실행
"사용자 모드에서 커널 모드로 변경되는 경우
시스템 호출과 인터럽트 발생의 2가지 경우에만"
"특권 명령 종류
I/O 명령
하드웨어 제어 및 장치로부터의 입출력
Halt 명령
인터럽트 플래그 켜고 끄는 명령
타이머 설정 명령
컨텍스트 스위칭 명령"
커널은 부팅 시에 커널 공간에 적재 함수들과 데이터의 집합
커널 코드는 함수들의 집합
시스템 호출 사용자 공간의 코드에서 커널 서비스를 요청하는 과정
인터럽트 CPU가 현재 일을 중단하고 다른 일을 하도록 시키는 비동기적 방법
인터럽트는 다중프로그래밍의 키
인터럽트가 없다면 다중프로그래밍 운영체제의 구현은 사실상 거의 불가능.
"
프로그램은 하드디스크 등의 저장 매체에 실행 파일의 형태로 저장된 소프트웨어이다"
"
프로세스는 프로그램이 메모리에 적재되어 실행 중인 상태이다"
"
코드 공간, 데이터 공간, 스택 공간, 힙 공간과 같은 자원을 할당 받는다"
"
운영체제는 프로그램을 메모리에 적재하고 프로세스로 다룬다"
"
운영체제는 프로세스에게 실행에 필요한 메모리를 할당하여 코드와 데이터
등 적재한다"
"
각 프로세스는 독립된 메모리 공간을 가지며, 다른 프로세스의 메모리 영역에 접근하는 것은 허용되지 않는다"
"
운영체제는 각 프로세스의 메모리 위치와 크기 정보를 관리한다"
"
운영체제는 프로세스마다 고유한 번호(프로세스 ID) 할당한다"
"
프로세스의 관한 모든 정보는 커널에 의해 관리된다"
"
프로세스는 실행-대기-잠자기-대기-실행-종료 등의 생명 주기를 가진다"
"
프로세스 생성, 실행, 대기, 종료 등의 모든 관리는 커널에 의해 수행된다"
"
운영체제는 커널 영역에 프로세스 테이블을 만들고, 프로세스들 목록을 관리한다"
"
프로세스 생성, 실행, 일시 중단 및 재개, 정보 관리, 프로세스 통신, 프로세스
동기화, 프로세스 중단, 프로세스 컨텍스트 스위칭과 같은 관리를 한다"
"
하나의 프로그램을 여러 번 실행될 때마다 독립된 프로세스가 생성된다"
"
이 프로세스들을 프로그램의 다중 인스턴스라고 부른다"
"
각 프로세스는 고유한 메모리 공간을 가지고 별개의 프로세스로 간주되지만, 프로그램 코드는 공유할 수 있다"
"
CPU가 주소선을 통해 액세스할 수 있는 전체 메모리 공간을 CPU 주소 공간(CPU address space)이라고 한다"
"
CPU가 주소선의 수에 의해 CPU 주소 공간 크기가 결정된다"
"
예를 들어 32비트 CPU는 32개의 주소선, 2^32개의 주소, 2^32 바이트, 4GB의 공간을 가지고 있다는 뜻이다"
"
CPU가 설치된 메모리의 주소 영역을 넘어 액세스하면 시스템 오류가 발생한다"
"
프로세스는 코드(code) 영역, 데이터(data) 영역, 힙(heap) 영역, 스택(stack) 영역으로 구성되어있다"
"
코드 영역은 사용자가 작성한 모든 함수의 코드나 호출한 라이브러리 함수들의 코드와 같은 실행될 프로그램 코드가 적재되는 영역이다"
"
데이터 영역은 프로그램에서 고정적으로 만든 전역 변수 및 정적 데이터를 저장하는 공간으로, 프로세스가 메모리에 적재될 때 할당되고 종료 시 소멸된다"
"
힙 영역은 프로세스 실행 중에 동적으로 메모리를 할당받는 공간으로, malloc() 또는 new 같은 함수로 할당하며, 할당은 상위 주소에서 하위 주소로 진행된다"
"
스택 영역은 함수가 실행될 때 사용될 데이터를 위해 할당된 공간으로, 매개변수, 지역변수, 함수 종료 후 돌아갈 주소 등을 가지고 있다"
"
함수 호출 시 상위 주소로 공간이 할당되고, 함수가 반환(return)되면 해당 공간이 해제된다"
"
프로세스 주소 공간은 프로세스가 실행 중에 접근할 수 있도록 허용된 주소의 최대 범위이다"
"
프로세스 주소 공간은 논리 공간(가상 공간)이며, 0번지에서 시작하여 연속적인 주소를 가지고 있다"
"
프로세스 주소 공간의 크기는 CPU가 액세스할 수 있는 전체 메모리 크기를 나타낸다"
"
프로세스 주소 공간은 프로세스가 액세스할 수 있는 최대 크기를 의미하며, 프로세스의 실제 크기는 적재된 코드, 전역 변수, 힙 영역(동적 메모리), 스택 영역의 합으로 구성된다"
"
프로세스 주소 공간은 사용자 공간과 커널 공간으로 나뉜다"
"
사용자 공간에는 프로세스의 코드, 데이터, 힙, 스택 영역이 포함되며, 이들은 특정 순서로 할당된다"
"
코드와 데이터 영역은 프로세스가 메모리에 적재될 때 크기가 결정된다"
"
힙은 데이터 영역 바로 다음부터 높은 번지 방향으로 확장되며, 스택은 사용자 공간의 바닥에서 시작하여 낮은 번지 방향으로 확장된다"
"
커널 공간은 시스템 호출을 통해 프로세스가 접근하는 영역으로, 커널 코드, 커널 데이터, 커널 스택이 포함된다"
"
프로세스의 코드와 데이터 영역은 실행 중 크기가 변하지 않지만, 힙과 스택은 사용자 공간 내에서 동적 할당을 통해 확장될 수 있다"
"
각 프로세스는 독립된 사용자 공간을 소유하고, 시스템 전체에는 단일 커널 주소 공간이 있으며, 커널 공간은 모든 프로세스가 공유한다"
"
커널 코드는 사용자 프로세스가 소유한 매핑 테이블을 사용하여 물리 메모리에 위치한다"
"
이는 사용자 공간과 커널 공간이 하나의 가상 주소 영역 내에서 관리된다는 것을 의미한다"
"
프로세스의 주소 공간은 개발자나 사용자가 인지하는 가상 공간을 말하며, 이는 프로세스가 연속적인 메모리 영역에 최대 메모리 크기까지 접근할 수 있다고 상상하는 것이다"
" 
실제로는 물리 메모리의 크기가 주소 공간보다 작을 수 있으며, 프로세스의 코드, 데이터, 힙, 스택이 물리 메모리 전체에 분산되어 저장된다"
"
각 프로세스는 별도의 가상 주소 공간을 가지기 때문에 프로세스 간 주소 공간은 충돌하지 않는다"
"
이는 가상 주소가 물리 주소로 매핑되면서, 서로 다른 프로세스의 메모리 영역이 물리 메모리에서 겹치지 않도록 보장하기 때문이다"
"
프로세스 테이블은 시스템의 모든 프로세스들을 관리하기 위한 표이며, 시스템에 한 개만 보유하고 있으며, 구현 방식은 운영체제마다 다르다"
"
프로세스 제어 블록(PCB)은 프로세스에 관한 정보를 저장하는 구조체로, 프로세스당 하나씩 존재한다"
"
프로세스가 생성될 때 만들어지고 종료되면 삭제되며, 커널에 의해 생성, 저장, 읽기, 프로세스 관리 등을 위해 사용된다"
"
커널 영역, 커널 코드(커널 모드)만이 프로세스 테이블과 PCB에 액세스 가능하다"
"
프로세스는 탄생부터 종료까지 여러 상태를 거치며 실행되며, 이 상태 정보는 프로세스 제어 블록(PCB)에 기록되어, 상태가 바뀔 때마다 갱신된다"
"
프로세스의 상태 중 New(생성 상태)는 메모리 할당 및 필요한 자원이 적재된 상태로, PCB에 New 상태로 등록되고, 실행 준비를 마치면 Ready 상태로 바뀐다"
"
Ready(준비 상태)는 프로세스가 스케줄링을 기다리는 단계로 프로세스는 준비 큐에서 대기한다"
"
스케줄링 되면 Running 상태로 바뀌고, CPU에 의해 실행된다"
"
Running(실행 상태)는 프로세스가 CPU에 의해 현재 실행되고 있는 상태로, CPU의 시간할당량(타임슬라이스)이 지나면 다시 Ready 상태로 바뀌고 준비 큐에 삽입된다"
"
프로세스가 입출력을 시행하면 커널은 프로세스를 Blocked 상태로 만들고 대기 큐에 삽입된다"
"
Blocked/Wait(블록 상태)는 프로세스가 자원을 요청하거나, 입출력을 요청하고, 완료를 기다리는 상태이다"
"
입출력이 완료되면 프로세스는 Ready 상태로 바뀌고 준비 큐에 삽입된다"
"
Terminated/Zombie(좀비 상태)는 프로세스가 불완전 종료된 상태로, 프로세스가 차지하고 있던 메모리와 할당받았던 자원들을 모두 커널에 의해 반환된다"
"
프로세스 테이블의 항목과 PCB가 여전히 시스템에서 제거되지 않은 상태로, 프로세스가 남긴 종료 코드를 부모 프로세스가 읽어가지 않아 완전히 종료되지 않은 상태이다"
"
Terminated/Out 상태는 프로세스가 종료하면서 남긴 종료 코드를 부모 프로세스가 읽어 가서 완전히 종료된 상태로, 프로세스 테이블의 항목과 PCB가 시스템에서 완전히 제거된 상태이다"
"
과거 운영체제에서는 프로세스가 실행 단위였으므로, 프로세스 스케줄링은 Ready 상태의 프로세스 중에서 실행할 프로세스를 선택하는 것이었다"
" 
그러나 오늘날의 운영체제에서는 스레드가 실행 단위가 되어, 프로세스 스케줄링이 사라지고, 대신 Ready 상태의 스레드 중에서 실행할 스레드를 선택하는 스레드 스케줄링이 주로 사용된다"
"
이에 따라 프로세스는 스레드들에게 공유 자원을 제공하는 컨테이너 역할을 수행하는 구조로 바뀌었다"
"
프로세스는 일반적으로 부모-자식 관계를 가진다"
"
Windows에서는 모든 프로세스가 동등하여 계층 관계가 없지만, 다른 시스템에서는 프로세스가 부모-자식 구조로 계층을 이룬다"
"
시스템 부팅 시 최초로 실행되는 #0 프로세스는 조상 프로세스로, 모든 다른 프로세스는 이 조상 프로세스에서 유래한다"
"
부모 프로세스는 여러 개의 자식 프로세스를 가질 수 있으며, 모든 프로세스는 #0 프로세스를 제외하고 부모 프로세스를 가진다"
"
자식 프로세스는 부모 프로세스에 의해 생성되며, 프로세스 생성은 시스템 호출을 통해 이루어지며, fork(), clone() 등은 자식 프로세스를 만드는 데 사용된다"
"
리눅스에서 프로세스 생성 사례는 #0 프로세스, #1 프로세스, #2 프로세스가 있다"
"
swapper/idle 프로세스(#0 프로세스)는 시스템 부팅 시 최초로 실행되는 프로세스로, 수작업으로 생성된다"
"
init 프로세스(#1 프로세스)는 시스템 부팅 후 생성되는 모든 사용자 프로세스의 조상으로, 수작업으로 생성된다"
"
kthreadd 프로세스(#2 프로세스)는 커널 모드에서만 실행되는 모든 커널 프로세스의 조상으로, 수작업으로 생성된다"
"
fork()는 자식 프로세스를 생성하는 시스템 호출이다"
"
exit()는 현재 프로세스의 종료를 커널에 알리는 시스템 호출로, 이를 통해 커널이 해당 프로세스의 종료를 처리하는 코드를 실행한다"
"
Wait()는 부모가 자식 프로세스의 종료를 기다리고 확인하는 시스템 호출이다"
"
자식 프로세스가 부모 프로세스보다 먼저 종료한 경우 좀비 상태가 지속된 후 자식 프로세스의 종료가 확인되면 완전 종료가 된다"
"
프로세스가 종료하면 프로세스 제어 블록(PCB)에 종료 코드(exit status)가 저장되고, 프로세스 상태는 'Terminated'로 표시된다"
"
프로세스에게 할당된 모든 메모리는 반환되지만, PCB와 프로세스 테이블의 항목은 제거되지 않는다"
"
부모 프로세스는 wait() 시스템 호출을 통해 자식 프로세스의 종료 코드를 읽어야 한다"
"
자식 프로세스가 종료되면 부모 프로세스에게 SIGCHLD 신호가 전송되고, 부모 프로세스가 이 신호를 받았을 때 wait()을 호출하지 않으면, 자식 프로세스는 계속 좀비 상태로 남아 있게 된다"
"
좀비 프로세스를 제거하는 방법은 부모 프로세스에게 SIGCHLD 신호 보내어 wait()을 호출하거나 부모 프로세스를 강제 종료하여 좀비 프로세스가 init 프로세스의 자식이 되고 init 프로세스가 wait()을 호출하여 좀비 프로세스를 제거하는 방법이 있다"
"
고아 프로세스(Orphan Process)는 부모가 먼저 종료한 자식 프로세스이다"
"
부모 프로세스가 종료할 때, 커널은 exit() 시스템 호출을 통해 부모 프로세스에 자식 프로세스가 있는지 확인한다"
" 
자식 프로세스가 있으면, 커널은 자식을 init 프로세스에게 입양시킨다"
"
그러나 일부 운영체제나 특정 쉘에서는 부모 프로세스가 종료될 때 모든 자식 프로세스를 강제 종료시킬 수도 있다"
"
백그라운드(background) 프로세스는 터미널에서 실행되었지만, 터미널 사용자와의 대화가 없는 채 실행되거나, 사용자와 대화없이, 입력없이 실행되는 프로세스이다"
"
포그라운드(foreground) 프로세스는 실행되는 동안 터미널 사용자의 입력을 독점하는 프로세스이다"
"
CPU 집중 프로세스(CPU intensive/bound process)는 CPU 작업을 하는데 대부분의 시간을 보내는 프로세스로, 배열 곱, 인공지능 연산, 이미지 처리 등의 작업을 하며, CPU 속도가 성능을 좌우한다"
" 
I/O 집중 프로세스(I/O intensive/bound process)는 입출력 작업을 하느라 대부분의 시간을 보내는 프로세스로, 네트워크 전송, 파일 입출력에 집중된 프로세스이며, 입출력 장치나 입출력 시스템의 속도가 성능을 좌우한다"
"
운영체제 스케줄링에서는 I/O 집중 프로세스가 CPU 집중 프로세스보다 우선순위를 가진다"
"
I/O 작업 중 다른 프로세스가 CPU를 사용할 수 있게 하여 사용자 응답 시간을 줄이고, 시스템의 처리율을 높인다"
"
"
"
프로세스의 문제점은 프로세스 생성과 컨텍스트 스위칭은 메모리 할당, 부모 프로세스 복사, PCB 생성, CPU 레지스터 및 매핑 테이블 전환으로 인한 오버헤드가 발생하며, 프로세스 간 통신의 어려움은 독립적인 주소 공간을 갖고 있어 직접적인 메모리 접근이 불가능하며, 이를 위한 별도의 통신 방법이 필요하나 이는 코딩이 어렵고 실행 속도가 느리며 운영체제 호환성이 부족하다"
"
스레드의 출현은 프로세스를 사용하는 문제점을 해결하기 위해 고안되었으며, 프로세스보다 더 작은 실행 단위가 필요한 상황에서 멀티스레드 운영체제에서 스레드를 실행 단위로 다루어 오버헤드를 저감하고 빠른 컨텍스트 스위칭을 가능케 하여 프로세스의 복잡한 통신 방법과 느린 실행 속도, 코딩의 어려움을 해소한다"
"
스레드는 실행 단위이자 스케줄링 단위로, 응용프로그램 개발자에게는 작업을 만드는 단위로 작용하며, 운영체제에게는 CPU를 할당하는 스케줄링 단위로 동작한다"
" 
각 스레드는 코드, 데이터, 힙, 스택을 가진 실체이며, 각 스레드마다 정보를 저장하는 구조체인 TCB(Thread Control Block)가 존재한다"
"
프로세스는 스레드들의 컨테이너로, 스레드는 독립적으로 존재할 수 없고 반드시 프로세스 내에서 존재하며, 프로세스는 적어도 1개 이상의 스레드로 구성되며, 프로세스가 생성될 때 운영체제에 의해 자동으로 1개의 스레드인 메인 스레드가 생성된다"
"
커널은 CPU 스케줄링 시 전체 TCB 중 하나를 선택하여 스레드를 실행시킨다"
"
프로세스는 스레드들의 공유 공간(환경)을 제공한다"
"
스레드는 프로세스의 주소 공간 내에 코드가 적재되며, 프로세스의 환경을 공유하고 있어 전역 변수에 접근 가능하며, 모든 스레드는 프로세스의 코드, 데이터, 힙을 공유하고 각각의 스레드는 독립적인 스택을 갖고 있어서 프로세스 내의 스레드 간 통신이 용이하다"
"
스레드는 응용프로그램에서 실행할 작업을 함수로 작성하고, 운영체제에게 스레드 생성을 요청하여 함수의 주소를 스레드 실행 시작 주소로 등록하고 TCB 리스트로 스레드를 관리하며 스레드 단위로 스케줄한다"
" 
스레드의 생명주기는 스레드로 만든 함수가 종료하면 해당 스레드가 종료되고, 이에 따라 TCB 등 스레드 관련 정보가 모두 제거되며, 모든 프로세스에 속한 스레드가 종료될 때 해당 프로세스도 종료된다"
"
멀티스레드 C 응용프로그램 예시는 리눅스에서 POSIX 표준의 pthread 라이브러리를 사용하여 메인 스레드와 calcThread 두 개의 스레드로 구성된다"
"
메인 함수는 메인 스레드 코드를 실행하고, calcThread 스레드를 생성한 후 해당 스레드의 종료를 기다린 후 전역 변수 sum의 값을 출력한다"
" calcThread 함수는 스레드 코드로, 정수를 매개변수로 받아 1에서 해당 정수까지의 합을 계산하여 전역 변수 sum에 저장한다"
 이 sum 변수는 calcThread와 main 스레드에서 모두 접근할 수 있다
"
프로세스가 생성되면 main() 함수가 실행되며, 이로 인해 main 스레드가 자동으로 생성된다"
" 
스레드 코드는 함수로 만들어지며, 여기서는 calcThread() 함수가 이 역할을 한다"
"
스레드는 pthread_create() 라이브러리 함수나 시스템 호출을 통해 생성되며, 각 스레드마다 1개의 TCB가 생성된다"
" 
TCB에는 스레드의 시작 주소와 컨텍스트 스위칭 시 재개할 주소가 저장되어 있다"
"
스레드는 스케줄링되고 실행되는 실행 단위이며, 프로세스는 스레드들의 컨테이너이다"
"
프로세스는 스레드들에게 공유 공간을 제공하며, 프로세스의 코드와 전역 변수는 모든 스레드에 의해 공유되며, 이 예시에서는 main 스레드와 calcThread 스레드가 sum 변수를 공유한다"
"
concurrency(동시성)는 1개의 CPU에서 2개 이상의 스레드가 동시에 실행되는 상태로, 스레드가 입출력으로 실행이 중단될 때 다른 스레드가 실행되며, CPU는 타임 슬라이스 단위로 스레드를 번갈아가며 실행시킨다"
"
parallelism(병렬성)은 2개 이상의 스레드가 다른 CPU에서 같은 시간에 동시에 실행되는 상태로, parallelism 사례에서는 3개의 스레드가 3개의 CPU에 의해 동시 실행된다"
"
스레드 주소 공간은 스레드가 실행 중에 사용하는 메모리 공간으로, 스레드의 코드, 데이터, 힙, 스택 영역 등이 포함되며, 이는 프로세스의 주소 공간 내에 형성된다"
"
스레드 주소 공간의 요소는 스레드의 사적 공간으로 스레드 코드와 스택, 그리고 스레드 로컬 스토리지(TLS)를 포함하며, 스레드 사이의 공유 공간으로 프로세스의 코드, 데이터 공간(로컬 스토리지 제외), 그리고 힙 영역이 포함된다"
"
스레드 코드 영역은 스레드가 실행할 작업의 함수를 담고 있으며, 이는 프로세스의 코드 영역을 사용하며, 스레드는 프로세스의 코드 영역에 있는 다른 모든 함수를 호출할 수 있다"
"
스레드 데이터 영역은 스레드가 사용할 수 있는 데이터 공간으로, 이는 프로세스의 데이터 영역을 활용하며, 개별 스레드 전용 전역 변수와 모든 스레드에 공유되는 전역 변수로 구성되어 있어, 스레드 간의 효율적인 통신을 가능케 한다"
"
스레드 힙은 모든 스레드가 동적으로 할당되는 공간으로, 프로세스의 힙 공간을 활용하여, 스레드가 malloc()를 호출하면 해당 공간에서 할당받아지며, 동적 메모리의 주소만으로도 다른 스레드가 접근 가능한 통신 공간이다"
"
스레드 스택은 스레드가 생성될 때 프로세스의 사용자 스택의 일부를 할당받으며, 시스템 호출로 커널에 진입할 때는 해당 스레드를 위한 스택을 할당받는다"
"
스레드는 생성, 실행, 중단, 실행, 소멸의 여러 상태를 거치며, 이러한 상태는 해당 스레드의 TCB에 저장되며, 스레드가 스케줄 되기를 기다리는 상태인 준비 상태, 스레드가 CPU에 의해 실행 중인 상태인 실행 상태, 입출력을 요청, sleep()과 같은 시스템 호출로 중단된 상태인 대기 상태, 스레드가 종료한 상태인 종료 상태로 구분된다"
"
프로세스 생성 시 main 스레드가 자동으로 생성되며, 추가적인 스레드는 시스템 호출이나 라이브러리 함수를 사용하여 생성된다"
"
프로세스 종료는 exit() 시스템 호출로 이뤄지며, 모든 스레드 종료 시 프로세스도 함께 종료되고, 스레드 종료는 pthread_exit()과 같은 함수를 호출하여 해당 스레드만 종료된다"
"
스레드 조인은 스레드가 다른 스레드의 종료를 대기하는 것으로, 주로 부모 스레드가 자식 스레드의 종료를 대기한다"
"
스레드 양보는 스레드가 자발적으로 실행을 중단하고 다른 스레드를 스케줄하도록 요청하는 것을 말한다"
"
스레드 컨텍스트는 스레드의 실행 중인 상태 정보를 나타내며, CPU 레지스터의 값, PC와 SP 레지스터의 주소, 그리고 데이터/상태 레지스터 등을 포함한다"
" 
스레드의 실행 중인 상태 정보는 스레드의 TCB에 저장되며, CPU는 이 정보를 저장하여 필요할 때 스레드의 실행 상태를 저장하거나 복구할 수 있다"
"
TCB(스레드 제어 블록)은 스레드를 실행 단위로 다루기 위해 스레드에 관한 정보를 담은 구조체로, 스레드 엔티티로서 커널 영역에 의해 만들어지고 관리되며, 컨텍스트 스위칭시 TCB가 수정되고 스레드가 생성될 때 커널에 의해 만들어지도 스레드가 소멸되면 함께 소멸된다"
"
TCB 들은 linked list로 연결되며, 커널은 CPU 스케줄링 시 전체 TCB 중 하나를 선택하여 스레드를 실행시킨다"
"
준비 리스트는 준비 상태에 있는 스레드들의 TCB를 연결하여 관리하는 linked list로, 스레드 스케줄링 시 이 리스트의 TCB 중 하나를 선택한다"
" 
블록 리스트는 블록 상태에 있는 스레드들의 TCB를 연결하여 관리하는 linked list로, 대기하는 자원이나 I/O 장치별로 따로 구성된다"
"
스레드 컨텍스트 스위칭은 현재 실행중인 스레드를 중단시키고, 해당 스레드의 CPU 컨텍스트를 TCB에 저장한 후, 다른 스레드의 TCB에 저장된 컨텍스트를 CPU에 적재하여 CPU 할당을 전환하는 작업이다"
"
스레드 스위칭이 발생하는 경우는 스레드가 자발적으로 다른 스레드에게 양보하거나(yield(), sleep(), wait() 등의 시스템 호출을 통해) 시스템 호출로 블록되는 경우(read(), write() 등 I/O가 발생하거나 대기할 수 밖에 없는 경우), 타임 슬라이스 소진(타이머 인터럽트에 의해 체크됨), 그리고 I/O장치로부터 인터럽트가 발생하는 경우이다"
"
I/O장치로부터 인터럽트가 발생하면 현재 실행 중인 스레드보다 높은 우선순위의 스레드가 블록 상태에서 I/O 완료를 기다리는 경우이며, 이로 인해 인터럽트를 받은 스레드가 강제로 중단되어 높은 우선순위의 스레드로 스레드 스위칭이 발생한다"
"
스레드 스위칭은 프로세스가 시스템 호출을 하여 커널이 시스템 호출을 처리하거나, 인터럽트가 발생하여 인터럽트 서비스 루틴이 실행되는 도중 커널 코드에서 발생한다"
"
스레드 스위칭 과정 중 CPU 레지스터 저장 및 복귀는 현재 실행 중인 스레드의 컨텍스트를 TCB에 저장하고, 다른 스레드의 컨텍스트를 CPU에 적재하여 중단된 위치에서 실행을 재개할 수 있도록 프로그램 카운터(PC) 및 스택 포인터(SP) 등의 정보로 자신의 이전 스택을 되찾아 이전 중단될 때 함수의 매개변수나 지역변수들이 그대로 되찾을 수 있다"
"
스레드 스위칭 과정 중 커널 정보 수정은 커널이 TCB-A와 TCB-B에 대한 스레드 상태 정보 및 CPU 사용 시간을 수정하고, TCB-A를 준비 리스트나 블록 리스트로 이동시키고, TCB-B를 준비 리스트에서 분리한다"
"
컨텍스트 스위칭은 CPU 작업이므로 CPU 시간을 소모하며, 스위칭 시간이 길거나 빈번한 경우 컴퓨터 처리율이 저하되는 오버헤드가 있다"
"
동일한 프로세스 내 다른 스레드로 스위칭 되는 경우 컨텍스트 저장 및 복귀, TCB 리스트 조작, 그리고 캐시 플러시와 채우기 시간이 있다"
"
다른 프로세스의 스레드로 스위칭하는 경우, 다른 프로세스로 교체되면 CPU가 실행하는 주소 공간이 바뀌기 때문에 시스템 내에 현재 실행 중인 프로세스의 매핑 테이블을 새로운 프로세스의 매핑 테이블로 교체되는 추가적인 메모리 오버헤드와 프로세스가 바뀌고 새 프로세스의 스레드가 실행을 시작하면 CPU 캐시 미스 발생, 캐시가 채워지는데 상당한 시간 소요되는 캐시 오버헤드가 발생한다"
"
스레드 스케줄링 주체에 따라 커널에 의해 스케줄링되는 스레드인 커널 레벨 스레드와 스레드 라이브러리에 의해 스케줄링되는 스레드인 사용자 레벨 스레드가 있다"
"
커널 레벨 스레드는 시스템 호출을 통해 생성되며, 커널이 관리하고 스케줄링하는 스레드로, 스레드 정보(TCB)는 커널 공간에 생성되어 소유된다"
"
사용자 레벨 스레드는 응용프로그램이 라이브러리 함수를 호출하여 생성되며, 사용자 레벨 스레드 정보(U-TCB)는 사용자 공간에 생성되고 소유된다"
" 
사용자 레벨 스레드는 스레드 라이브러리의 스케줄러 코드에 의해 스케줄되며, 스레드 주소 공간은 사용자 공간에 존재한다"
"
사용자 레벨 스레드는 커널 레벨 스레드보다 100배 이상 빠르다고 알려져 있고, 스레드 라이브러리를 이용하여 작성하기 쉽고, 스레드 생성 속도가 빠르며 운영체제 상관없이 작성 가능하므로 높은 이식성과 스레드를 지원하지 않는 운영체제에서도 가능하다"
"
사용자 레벨 스레드는 멀티 CPU 컴퓨터나 멀티 코어 CPU에서 멀티스레드의 병렬처리가 안 되고, 동시성을 가지고 있으며 하나의 사용자 레벨 스레드가 시스템 호출 도중 입출력 등으로 인해 중단되면 프로세스의 모든 사용자 레벨 스레드가 중단된다"
"
커널 레벨 스레드는 커널 내에 상당 시간 지연이 있고, 시스템 호출을 사용하여 스레드를 생성하기 때문에 스레드 생성 속도가 느리며 운영체제마다 시스템 호출이 다르기 때문에 이식성이 낮다"
"
커널 레벨 스레드는 높은 병렬성으로 커널 레벨 스레드들이 서로 다른 CPU나 서로 다른 코어에서 병렬로 실행가능하며 병렬성을 가지고 있으며 하나의 커널 레벨 스레드가 시스템 호출 도중 입출력 등으로 인해 중단되어도 해당 스레드만 중단되고 커널 코드의 실행 시간이 증가하여 시스템 전체에 부담이 된다"
"
멀티스레드의 구현은 응용프로그램에서 작성한 스레드가 시스템에서 실행되도록 하는 방법으로, 스레드 라이브러리와 커널의 시스템 호출이 상호 협력하여 사용자가 만든 스레드가 스케줄되고 실행되도록 구현된다"
"
멀티스레드 구현 방법의 세 가지는 N개의 사용자 레벨 스레드를 1개의 커널 레벨 스레드로 매핑하는 N:1 매핑, 1개의 사용자 레벨 스레드를 1개의 커널 레벨 스레드로 매핑하는 1:1 매핑, N개의 사용자 레벨 스레드를 M개의 커널 레벨 스레드로 매핑하는 N:M 매핑이다"
"
N:1 매핑에서는 운영체제가 모든 프로세스를 단일 스레드 프로세스로 취급하고, 각 프로세스마다 1개의 커널 레벨 스레드를 생성하여 모든 사용자 레벨 스레드를 하나의 커널 레벨 스레드에 매핑한다"
"
N:1 매핑의 장점은 단일 코어 CPU에서 멀티스레드 응용프로그램의 실행 속도가 전반적으로 빠르다는 것이며, 단점으로는 멀티 코어 CPU에서의 효율성이 떨어진다는 점과 하나의 사용자 레벨 스레드가 blocked되면 프로세스 전체가 블록된다는 점이 있다"
"
1:1 매핑은 사용자 레벨 스레드 당 1개의 커널 레벨 스레드(TCB)가 생성되며, 사용자 레벨 스레드는 매핑된 커널 레벨 스레드가 스케줄되면 실행된다"
"
1:1 매핑의 장점은 개념이 단순하여 구현이 용이하고, 멀티 코어 CPU에서 멀티스레드 응용프로그램에게 높은 병렬성을 제공하며, 하나의 사용자 레벨 스레드가 블록되어도 응용프로그램 전체가 블록되지 않는다는 것이며, 단점은 커널에게는 부담스러운 정책이며, 사용자 레벨 스레드가 많아지면 모두 커널의 부담이 된다"
"
N:M 매핑은 N개의 사용자 레벨 스레드를 M개의 커널 레벨 스레드에 일대일로 매핑하는 구조로, 2단계 스케줄링을 가진다"
"
N:M 매핑의 장점은 커널 엔티티 개수가 적어 커널의 부담이 적고, 단점은 구현이 복잡하여 현대 운영체제에서는 거의 사용되지 않는다"
"
멀티스레딩으로 응용 프로그램을 사용할 때의 장점은 높은 실행 성능과 병렬 실행이 가능해지며, 사용자에게 우수한 응답성을 제공하고, 서버 프로그램은 동시에 많은 사용자의 요청을 처리할 수 있어 우수한 응답성을 보입니다"
"
멀티스레딩으로 응용 프로그램을 사용할 때의 장점은 시스템 자원을 효율적으로 사용하며, 응용프로그램의 구조를 단순화하여 새로운 기능을 추가하기 쉬우며 확장성이 높아집니다"
" 추가로, 스레드를 이용한 통신은 쉽고 효율적으로 이루어집니다"
"
멀티스레딩을 할 때 주의할 점은 여러 개의 스레드 중 한 스레드가 fork()를 호출하면 새로 생성된 프로세스는 해당 스레드로만 구성되며, 이는 한 스레드가 exec()를 호출한 경우와 같이 현재 프로세스의 모든 스레드가 사라지는 문제를 야기할 수 있고, 또한 다수의 스레드가 공유 데이터에 액세스하는 경우 데이터 훼손이 발생할 수 있으므로 이를 해결하기 위해 동기화 기법을 사용해야 합니다"
"
"
"
컴퓨터 시스템 내 스케줄링으로 작업 스케줄링, CPU 스케줄링, 디스크 스케줄링, 프린트 스케줄링이 있다"
"다중 프로그래밍의 도입 목적은 CPU 유휴 시간을 줄여 CPU 활용률을 향상 시키는 것이며, 프로세스가 I/O를 요청하면 다른 프로세스에게 CPU를 할당시키는 것으로 구현할 수 있다"
다중 프로그래밍에는 디스크에서 메모리로 작업을 올릴ㄴO 작업이 순차적으로 섞여 있다
CPU burst는 프로그램 실행 중 CPU 연산(계산 작업)이 연속적으로 실행되는 상황이다
I/O burst는 프로그램 실행 중 I/O 장치의 입출력이 이루어지는 상황이다
CPU 스케줄링은 실행 준비 상태의 스레드 중 하나를 선택하는 과정으로 CPU 활용률을 극대화하고 컴퓨터 시스템 처리율을 향상시키는 것이 목적이다
"스케줄링 알고리즘의 목표와 평가 기준으로 전체 시간 중 CPU의 사용 시간의 비율을 높이는 CPU 활용률, 단위 시간당 프로세스의 처리 개수를 높이는 처리율, CPU를 스레드들에게 공평하게 배분하는 공평성, 응답시간, 대기시간, 소요시간, 컴퓨터 시스템의 특별한 목적을 달성하기 위해 우선 실행하는 시스템 정책 우선, CPU나 I/O 장치 등의 자원 활용률을 극대화하는 것이 있다"
대부분의 운영체제에서 하나의 스레드가 너무 오래 CPU를 사용하도록 허용하지 않기 때문에 타임 슬라이스를 도입하여 이를 조절한다
"타임 슬라이스(time slice)는 스케줄된 스레드에게 한 번 할당하는 CPU 시간으로, 타이머 인터럽트의 도움을 받아 타임 슬라이스 단위로 CPU 스케줄링을 하며 커널이 스케줄을 단행하는 주기 시간으로 볼 수 있다"
"타임 스케줄링은 타임 퀀텀, 타임 슬롯이라고도 하며 윈도우는 CPU를 점유할 수 있는 최대 시간이 20~120ms으로 제한되어 있고, 리눅스는 스케줄러 관련 설정으로 스케줄링 때마다 다르게 할 수 있다"
"CPU 스케줄링은 스레드가 시스템 호출을 완료하지 못하고 I/O 작업이 완료될 때 실행되며, 스레드를 블록 상태로 만들고 대기 큐에 넣고 다른 실행 가능한 스레드를 선택하여 CPU에 할당하여 CPU 활용률을 향상시킬 수 있다. 
CPU 스케줄링은 스레드가 yield() 시스템 호출 등을 통해 자발적으로 CPU를 반환할 때 실행되며, 커널은 현재 스레드를 준비 리스트에 넣고, 새로운 리스트를 선택할 수 있어 CPU의 자발적 양보가 가능하다. 
CPU 스케줄링은 스레드의 타임 슬라이스가 소진되어 타임 인터럽트가 발생할 때 실행되며, 균등한 CPU 분배를 목적으로 한다"
"CPU 스케줄링은 더 높은 순위의 스레드가 요청한 입출력 작업을 완료하여 인터럽트가 발생했을 때 실행되며, 현재 스레드를 강제 중단시켜 준비 리스트에 넣고 높은 순위의 스레드를 깨워 스케줄링하는 방식으로 우선순위를 지키기 위한 목적으로 사용된다"
스케줄링 담당하는 커널 스레드나 프로세스는 따로 존재하지 않는다
"스케줄링 코드는 커널 내 함수로 존재하고, 별도로 실행되는 프로세스나 스레드의 형태가 아니다"
스케줄링 코드는 시스템 호출이나 인터럽트 서비스 루틴이 끝나는 마지막 단계에서 실행된다
"디스패쳐 코드란 컨텍스트 스위칭을 실행하는 커널 코드(부분)로, 스케줄러에 의해 선택된 스레드를 CPU가 실행하도록 하는 작업을 수행하고 커널 모드에서 사용자 모드로 전환하고 이전에 중단된 스레드가 중단된 시점에서 다시 실행되기 위해 이전에 중단된 지점으로 점프한다"
디스패쳐 코드는 시스템의 효율성과 안정성에 큰 영향을 미친다
스케줄러와 디스패쳐 모두 실행 시간이 짧도록 작성된다
실행 중인 스레드의 강제 중단 여부에 따라 비선점 스케줄링과 선점 스케줄링으로 나눠진다
"비선점 스케줄링은 현재 실행 중인 스레드를 강제로 중단시키지 않는 타입으로, 일단 스레드가 CPU를 할당받아 실행을 시작하면, 완료되거나 CPU를 더 이상 사용할 수 없는 상황이 될 때까지 스레드를 강제 중단시키지 않고 스케줄링도 하지 않는 방식이다"
"비선점 스케줄링의 스케줄링 시점은 CPU를 더이상 사용할 수 없게 된 경우(I/O로 인한 블록 상태, sleep 등)나, 자발적으로 CPU 양보할 때, 실행 중 종료할 때이다"
선점 스케줄링은 현재 실행중인 스레드를 강제 중단시키고 다른 스레드 선택하여 CPU를 할당하는 것이다
"선점 스케줄링의 스케줄링 시점은 타임슬라이스가 소진되어 타이머 인터럽트가 발생될 때나 인터럽트나 시스템 호출 종료 시점에서, 더 높은 순위의 스레드가 준비 상태일 때일 때이다"
기아란 스레드가 스케줄링에서 선택되지 못한 채 오랜 동안 준비 리스트에 있는 상황이다
"기아가 발생할 수 있는 경우로는 우선순위를 기반으로 하는 시스템에서, 더 높은 순위의 스레드가 계속 시스템에 들어오는 경우이거나 짧은 스레드를 우선 실행시키는 시스템에서 자신보다 짧은 스레드가 계속 도착하는 경우에 발생한다"
스케줄링 알고리즘 설계 시 기아가 발생하지 않도록 설계하는 것이 바람직하다
"에이징은 기아의 해결책으로 스레드가 준비 리스트에 머무르는 시간에 비례하여 스케줄링 순위를 높이는 기법으로, 오래 기다리지만 언젠가 가장 높은 순위에 도달하는 것을 보장해준다"
FCFS 알고리즘은 비선점 스케줄링으로 도착한 순서대로 처리한다
Shortest Job First 알고리즘은 비선점 스케줄링으로 가장 짧은 스레드를 우선 처리한다
Shortest remaining time first 알고리즘은 선점 스케줄링으로 남은 시간이 짧은 스레드가 준비 큐에 들어오면 이를 우선 처리한다
라운드 로빈(Round robin)은 선점 스케줄링으로 스레드들을 돌아가면서 할당된 시간(타임 슬라이스)만큼 실행한다
"우선 순위 스케줄링(Priority Scheduling)은 선점, 비선점 모두 구현 가능하고, 우선 순위를 기반으로 하여 가장 높은 순위의 스레드를 먼저 실행한다"
"멀티 레벨 큐 스케줄링(Multilevel queue scheduling)은 선점, 비선점 모두 구현 가능하고 스레드와 큐 모두 n개의 우선순위 레벨로 할당하고 스레드는 자신의 레벨과 동일한 큐에 삽입한다"
"멀티 레벨 피드백 큐(Multilevel feedback queue scheduling)는 선점, 비선점 모두 구현 가능하고 각 큐는 다른 우선순위 레벨을 가지며, 스레드는 최고 우선순위 큐에 진입하고 타임슬라이스가 끝나면 낮은 큐로 이동하며, 낮은 큐에 오래 머물면 다시 높은 큐로 이동한다"
"FCFS 스케줄링의 스케줄링 파라미터는 스레드 별 도착이간이고 스레드 우선 순위가 없고, 스레드가 오류로 인해 무한 루프를 실행하지 않는 이상 기아가 발생하지 않는다"
"FCFS 스케줄링은 처리율이 낮으며 호위 효과(긴 스레드가 CPU를 오래 사용하면, 늦게 도착한 짧은 스레드 오래 대기하는 것)가 발생한다"
"SJF(Shortest Job First)는 최단 작업 우선 스케줄링으로 스레드가 도착할 때 예상 실행 시간이 짧은 순으로 큐에 삽입하고, 큐의 맨 앞에 있는 스레드를 선택한다"
SJF 스케줄링 파라미터는 스레드 별 예상 실행 시간이지만 이 시간을 아는 것은 불가능하다
"SJF 스케줄링의 스레드 우선 순위는 없으며, 짧은 스레드가 계속 도착하면, 긴 스레드는 실행 기회를 언제 얻을 지 예측할 수 없지만, 짧은 스레드가 먼저 실행되므로 평균 대기 시간이 최소화된다"
SJF 스케줄링의 문제점은 실행 시간의 예측이 불가능하므로 현실에서는 거의 사용되지 않는다
"SRTF(Shortest remaining time first) 알고리즘은 실행 시간에 짧은 순으로 스레드들을 큐에 삽입, 한 스레드가 끝나거나 실행 시간이 더 짧은 스레드가 도착할 때, 가장 짧은 스레드 선택하고, 큐의 맨 앞에 있는 스레드를 선택하여 실행한다"
"SRTF의 스케줄링 파라미터는 스레드 별 예상 실행 시간과 남은 실행 시간 값인데 이것을 아는 것은 불가능하고, 스레드 우선 순위는 없다"
"SRTF은 실행 시간이 짧은 스레드가 먼저 실행되므로 평균 대기 시간 최소화 되지만, 실행 시간 예측이 불가능하므로 현실에서는 거의 사용되지 않는다"
RR(Round-robin) 스케줄링은 스레드들에게 공평한 실행 기회를 주기 위해 도착하는 순서대로 스레드들을 큐에 삽입하고 스레드가 타임 슬라이스를 소진하면 큐 끝으로 이동한다
"라운드 로빈의 스케줄링 파라미터는 타임 슬라이스이고 스레드 우선 순위가 없고, 타임 슬라이스가 정해져 있기 때문에 일정 시간이 지난 스레드는 반드시 실행된다"
"라운드 로빈은 공평하고, 기아 현상이 없으며 구현이 쉽지만, 잦은 전체 스케줄링 오버헤드 크고, 특히 타임 슬라이스가 작을 때 더욱 크다"
"라운드 로빈은 타임 슬라이스가 크면 FCFS에 가깝고, 적으면 SJF,SRTF에 가까우며, 늦게 도착한 짧은 스레드는 FCFS보다 빨리 완료되고, 긴 스레드는 SJF보다 빨리 완료된다"
"우선순위(Priority) 스케줄링은 현재 스레드가 종료되거나 더 높은 순위의 스레드가 도착할 때, 가장 높은 순위의 스레드 선택하고, 모든 스레드에 고정 우선 순위 할당, 종료 때까지 바뀌지 않는다"
"우선순위 스케줄링의 스케줄링 파라미터는  스레드 별 고정 우선 순위이고, 스레드 우선 순위가 존재한다"
"우선순위 스케줄링은 높은 순위의 스레드가 계속 도착하는 경우, 실행 기회를 언제 얻을 지 예상할 수 없기 때문에 기아가 발생할 수도 있지만, 큐 대기 시간에 비례하여 일시적으로 우선순위를 높이는 에이징 방법으로 해결 가능하다"
우선순위 스케줄링은 높은 우선순위의 스레드일 수록 대기 혹은 응답시간이 짧으며 스레드별 고정 우선 순위를 가지는 실시간 시스템에서 사용된다
"MLQ(멀티 레벨 큐) 스케줄링은 스레드들을 n개의 우선순위 레벨로 구분, 레벨이 높은 스레드를 우선 처리하는 목적으로 설계되었으며, 스레드는 도착 시 우선 순위에 따라 해당 레벨 큐에 삽입되고 다른 큐로 이동할 수 없다"
"MLQ 스케줄링의 스케줄링 파라미터는 스레드의 고정 우선 순위이고, 스레드 우선 순위가 존재한다"
MLQ 스케줄링은 높은 순위의 스레드가 계속 도착하는 경우 실행 기회를 언제 얻을 지 예상할 수 없어 기아가 발생할 수 있다
MLQ 스케줄링은 스레드의 고정 순위를 가진 시스템에서 활용될 수 있다
"MLFQ(멀티 레벨 피드백 큐) 스케줄링은 기아를 없애기 위해 여러 레벨의 큐 사이에 스레드 이동 가능하도록 설계되었으며, 짧은 스레드와 I/O가 많은 대화식 스레드를 우선 처리하여 스레드의 평균 대기 시간을 줄입니다"
"MLFQ 스케줄링은 n개의 고정 큐를 가지고 있으며, 큐마다 서로 다른 스케줄링 알고리즘이 있고, 큐마다 스레드가 머무를 수 있는 큐 타임 슬라이스 있다"
"MLFQ 스케줄링은 스레드 도착 시 최상위 레벨 큐에 삽입되고, 가장 높은 레벨 큐에서 스레드 선택하고 비어 있으면 그 아래의 큐에서 스레드 선택한다. 스레드의 CPU-burst가 큐 타임 슬라이스를 초과하면강제로 아래 큐로 이동시키고 스레드가 자발적으로 중단한 경우, 현재 큐 끝에 삽입한다"
"MLFQ 스케줄링에서 스레드가 I/O로 실행이 중단된 경우, I/O가 끝나면 동일 레벨 큐 끝에 삽입하고, 큐에 있는 시간이 오래되면 기아를 막기 위해 하나 위 레벨 큐로 이동한다. 최하위 레벨 큐는 주로 FCFS나 긴 타임 슬라이스의 RR로 스케줄되고, 스레드들은 다른 큐로 이동하지 못한다"
"MLFQ 스케줄링의 스케줄링 파라미터는 각 큐의 큐 타임 슬라이스이고, 스레드 우선 순위는 없다"
"MLFQ 스케줄링은 기아가 발생하지 않고, 큐에 대기하는 시간에 오래되면, 더 높은 레벨의 큐로 이동시키며(에이징 기법), 짧거나 입출력이 빈번한 스레드, 혹은 대화식 스레드를 높은 레벨의 큐에서 빨리 실행하여 CPU 활용률이 높다"
"리눅스의 CFS(Completely Fair Scheduling) 스케줄링은 CPU 사용 시간이 짧은 프로세스를 우선 선택하고, 프로세스가 선택되면 선택된 프로세스에게 타임 슬라이스를 다시 계산하여 설정하며, 타임 슬라이스는 스케줄될 때마다 달라진다"
"CFS 스케줄링은 CPU를 덜 할당받은 프로세스는, 시간이 지날수록 CPU 사용 시간이 상대적으로 낮아져 가까운 시간 내에 스케줄될 것이므로 기아는 발생하지 않으며, 시분할과 우선순위 스케줄링을 기반으로 공평성을 실현한다"
CFS 스케줄링은 스케줄링할 때마다 선택된 프로세스에게 할당할 타임 슬라이스를 새로 결정한다
"멀티코어 시스템에서 싱글 코어 CPU 스케줄링을 사용할 때 이전에 실행된 적이 없는 코어에 스레드가 배치될 때, 캐시에 새로운 스레드의 코드와 데이터로 채워지는 긴 경과 시간과 같은 컨텍스트 스위칭 오버헤드 증가 문제가 발생한다"
"멀티코어 시스템에서 싱글 코어 CPU 스케줄링을 사용할 때 코어별 부하 불균형 문제점이 있는데, 이는 스레드를 무작위로 코어에 할당하면, 코어마다 처리할 스레드 수의 불균형이 발생한다는 것이다"
"컨텍스트 스위칭 오버헤드 증가 문제를 해결하기 위해 코어 당 스레드 큐를 사용하거나, CPU 친화성(= 코어 친화성, CPU 피닝, 캐시 친화성)을 적용하여 스레드를 동일한 코어에서만 실행하도록 스케줄링한다. 
코어별 부하 불균형 문제를 해결하기 위해 부하 균등화 기법이나 감시 스레드가 짧거나 빈 큐를 가진 코어에 다른 큐의 스레드를 옮겨놓는 기법인 푸시 마이그레이션 기법, 코어가 처리할 스레드가 없게 되면, 다른 코어의 스레드 큐에서 자신이 큐로 가져와 실행시키는 기법인 풀 마이그레이션 기법을 사용하여 해결할 수 있다."
"프로세스는 서로 간의 주소 공간 접근, 데이터의 일관성, 자원 공유를 위해 프로세스 통신이 필요하다"
"응용 프로그램에서 공유 메모리 사용 절차는 공유 메모리를 생성하거나 이미 생성된 공유 메모리를 열고 shm_open() 로 공유 메모리에 대한 파일 디스크립터를 리턴 받고, ftruncate()로 공유 메모리의 크기를 설정 한 후 mmap()으로 공유 메모리를 현재 프로세스의 가상 주소 공간에 매핑한다. read(), write()로 공유 메모리에서 읽거나 쓰기를 진행하고, munmap()으로 공유 메모리의 사용 후 프로세스의 가상 주소 공간에서 분리하고 close()로 공유 메모리를 닫는다. shm_unlink()로 공유 메모리를 메모리를 완전히 제거한다"
신호 관련 system call 함수의 공유 메모리 사용 절차는 signal()로 신호 핸들러를 등록하는 시스템을 호출하고 kill()로 신호를 보내는 시스템을 호출할 수 있다
신호(signal)를 수신하는 3가지 경우는 프로세스 자신이 보낸 신호를 수신하거나 다른 프로세스로부터 신호를 수신하거나 커널로부터 예외 신호를 수신하는 경우가 있다
"신호 처리 과정은 프로세스 B는 signal() 시스템 호출을 이용해 신호를 수신했을 때 실행할 핸들러를 등록하고, 프로세스 A는 kill()을 호출하여 프로세스 B에게 신호를 보낸 후, 커널은 프로세스 B의 PCB에 신호 도착을 표시하며, 프로세스 B가 다시 실행되기 직전에 사용자 공간에 작성된 신호 핸들러가 실행된다"
파이프는 프로세스간 메시지로 데이터를 송수신하는 것으로 하나의 컴퓨터 내에서 프로세스 간 송수신 하는 익명의 파이프와 다른 컴퓨터 프로세스 간 송수신하는 이름을 가진 파이프가 있다
다수의 스레드가 동시에 공유 데이터에 쓰기를 접근하면 공유 데이터가 훼손되는 문제가 발생할 수 있다. 이때 스레드 동기화로 공유 데이터에 대한 다수의 스레드가 동시에 접근할 때 스레드의 실행을 제어하여 한 스레드가 공유 데이터를 배타적 독점적으로 접근하도록 순서화하고 임계구역에 대한 상호배제를 구현함으로써 해결할 수 있다
멀티 스레드의 경쟁 상황은 커널에 공유 데이터가 많아 자주 발생하기 때문에 조심하여야 한다
임계구역이란 공유 데이터에 접근하는 프로그램 코드들이고 상호배제는 임계구역에 먼저 스레드가 임계구역의 실행을 끝낼 때까지 다른 스레드가 진입하지 못하도록 보장하는 기술이다
일반 코드는 공유 데이터를 액세스하지 않는 코드이고 임계구역 진입 코드는 임계구역에 진입하기 전 필요한 코드 블록으로 현재 임계구역을 실행 중인 스레드가 있는지 검사한다
"임계구역 진출 코드는 임계구역의 실행을 마칠 때 실행되어야 하는 코드 블록으로, 진입 코드에서 대기중인 스레드가 임계구역에 진입할 수 있도록, 진입 코드에서 취한 조치를 해제하는 코드이다"
상호배제는 임계구역에 오직 1개의 스레드만 집입하도록 구현한다
"상호배제는 소프트웨어적 방법인 Peterson's 알고리즘 등과 하드웨어적 방법에 인터럽트 서비스 금지, 원자 명령으로 구현할 수 있다"
"인터럽트 서비스 금지 방법은 임계구역 진입 코드에서 인터럽트 서비스를 금지하는 명령을 실행하여, 타이머 인터럽트와 장치로부터의 인터럽트 발생 시 CPU가 이를 무시함으로써 임계구역을 실행하는 스레드가 중단되지 않도록 한다"
인터럽트 서비스의 문제점은 임계구역의 실행시간이 길어지면 모든 인터럽트가 무시되는 문제 발생한다는 것과 멀티 코어 CPU나 다중 CPU를 가진 시스템에서 활용할 수 없다는 것이다
"단순 lock 변수로 임계구역의 entry/exit 코드 작성하면 상호 배제가 성공할 수도 있지만, 하나의 인터럽트가 entry 코드 실행 도중 lock 변수를 변경하지 못하고 중단되고 다른 인터럽트가 entry 코드 내에 들어와서 lock 변수를 변경하고 중단되고 다시 원래의 인터럽트가 실행되어 임계구역에 진입하면 충돌하는 상황이 발생할 수 있다"
lock 변수를 이용하면 변수 값을 읽는 명령과 lock 변수에 1을 저장하는 2개의 명령 사이에 컨텍스트 스위칭이 될 때 문제가 발생할 수 있다
"원자 명령을 도입하여, lock 변수를 읽어들이는 명령과 lock 변수에 1을 저장하는 두 개의 명령을 하나의 기계어 명령어로 처리함으로써, 임계구역에 진입하는 과정을 원자적으로 실행한다. 이로써 타이머 인터럽트나 장치로부터의 인터럽트 발생 시에도 CPU가 이를 무시하고, 임계구역을 실행하는 스레드가 중단되지 않도록 보장된다"
멀티스레드 동기화란 상호배제 기반위에 자원을 사 용하려는 여러 스레드들이 자원을 원활히 공유하도록 하는 기법으로 동기화 프리미티브라고 부른다
"멀티스레드 동기화의 대표적인 기법으로 lock을 소유한 스레드만이 임계구역에 진입하는 locks 방식의 뮤텍스, 스핀락이 있고, n개의 자원을 사용하려는 m개의 멀티스레드의 원활한 관리를 하는 세마포 방식이 있다"
"뮤텍스(mutex)는 잠김/열림 중 한 상태를 가지는 lock 변수를 이용하여 한 스레드만 임계구역에 진입시키고, 다른 스레드는 큐에 대기 시킨다"
"뮤텍스의 구성 요소로는 락 변수, 대기 큐, entry 코드의 lock 연산(락이 열린 상태면 락을 잠그고 임계구역 진입하고 잠김 상태면 현재 스레드를 블록 상태로 만들고 대기 큐에 삽입)과 exit 코드의 unlock 연산(대기 큐에서 기다리는 스레드 하나 깨움)이 있다"
"뮤텍스를 이용한 동기화는 임계구역의 실행 시간이 짧을 때 유용하며, 락이 잠겨 있으면 대기 큐에서 대기하고 락이 해제되면 다시 실행되지만, 잠겨있는 시간보다 잠자고 깨는 데 걸리는 시간이 상대적으로 크다"
"스핀락(spinlock)은 busy-waiting lock 기법으로, 스레드가 큐에서 대기하지 않고 락이 열릴 때까지 계속 락 변수를 검사하며, 대기 큐 없이 busy-waiting으로 인해 CPU를 계속 소모하여 다른 스레드를 실행할 수 없게 하지만, 락을 소유한 스레드만 자원을 배타적으로 사용할 수 있도록 하는 동기화 기법으로, 공유 자원 하나 당 하나의 스핀락을 사용한다"
"스핀락의 구성 요소는 true 혹은 false 값을 가지는 락 변수로, true일 때는 락을 잠그고 소유하며, false일 때는 락을 열고 해제하는 것을 의미하며, lock 연산은 임계구역에 들어갈 때 실행되는 entry 코드로, 락이 잠긴 상태면 락이 풀릴 때까지 무한 루프로 lock 연산을 시도하고, 락이 열린 상태면 락을 잠김 상태로 바꾸고 임계구역을 실행하며, unlock 연산은 임계구역을 나올 때 실행되는 exit 코드로 락을 열린 상태로 변경한다"
"스핀락을 이용한 동기화는 뮤텍스의 non-blocking 모델로 busy-waiting을 사용하며, 단일 CPU(단일 코어)를 가진 운영체제에서는 비효율적이지만 멀티 코어 환경에서는 각기 다른 코어에서 락을 경쟁하는 스레드를 실행시킬 수 있어 효과적이고, 임계구역의 실행 시간이 짧을 때 특히 유용하지만 기아가 발생할 수 있는 단점이 있다"
"POSIX 표준 라이브러리를 이용한 스핀락 동기화는 pthread_spinlock_t 타입의 스핀락 변수를 생성하고, pthread_spin_init() 함수를 통해 스핀락 변수를 초기화하며, pthread_spin_lock()으로 스핀락을 잠그고, pthread_spin_unlock()으로 스핀락을 풀며, 사용이 끝난 스핀락 변수는 pthread_spin_destroy()를 통해 종료하는 방식으로 동작한다"
락이 잠기는 시간이 긴 경우는 CPU를 다른 스레드에게 양보하는 것이 효율적이기 때문에 뮤텍스를 사용하는 것이 적합하다
단일 CPU를 가진 시스템에선 뮤텍스가 적합하다
"멀티 코어(멀티 CPU)를 가진 시스템에서 스핀락을 사용하면, 잠자고 깨는 컨텍스트 스위칭 없이 바로 자원을 사용할 수 있으며, 임계구역을 가능한 짧게 작성하여 효율적인 동기화가 가능하다"
"사용자 응용프로그램에서는 뮤텍스를 사용하고, 커널 코드에서는 스핀락을 사용하는데, 이는 커널 코드나 인터럽트 서비스 루틴이 빨리 실행되어야 하며, 인터럽트 서비스 루틴 내에서는 잠잘 수 없기 때문이다"
"스핀락을 사용하면 기아가 발생할 수 있는데, 이는 스핀락이 무한 경쟁 방식이기 때문이며, 락을 소유한 스레드가 락을 풀지 않고 계속 실행하거나 종료해버리는 경우에도 기아가 발생할 수 있다"
"세마포(semaphore)는 n개의 공유 자원을 여러 스레드가 효율적으로 사용할 수 있도록 도와주는 멀티스레드 자원 관리 기법으로, 사용 가능한 자원의 개수를 나타내는 정수형 전역 변수(n으로 초기화되며 음수일 경우 자원을 기다리는 스레드의 수를 의미하는 카운터 변수), 자원을 할당받지 못한 스레드들이 대기하는 대기 큐, 자원 요청 시 실행되어 자원 사용 허가를 얻는 P 연산(wait 연산), 자원 반환 시 실행되어 자원 사용이 끝났음을 알리는 V 연산(signal 연산)으로 구성된다"
"세마포는 sleep-wait 세마포와 busy-wait 세마포로 구분되며, sleep-wait 세마포는 자원을 할당받지 못한 경우 P 연산에서 카운터를 감소시키고 대기 큐에서 잠자는 동작을 하며, V 연산에서는 카운터를 증가시키고 사용 가능한 자원이 있으면 잠자는 스레드를 깨우는 동작을 하며, busy-wait 세마포는 P 연산에서 사용 가능 자원이 생길 때까지 무한 루프를 돌며 대기하는 동작을 하며, 자원이 생기면 카운터를 감소시키고, V 연산에서는 카운터를 증가시킨다"
"세마포는 sem_t 구조체를 사용하여 구성되며, 세마포 조작 함수로는 초기화를 위한 sem_init(), 기능 소멸을 위한 sem_destroy(), P 연산을 수행하는 sem_wait() 함수로 sleep-wait 방식을 사용하여 가용 자원이 없으면 대기 큐에서 잠을 자는 동작을 하며, sem_trywait() 함수는 non-blocking call로 가용 자원이 있으면 카운터 값을 감소시키고 0을 반환하고, 없으면 카운터 값을 감소시키지 않고 -1을 반환한다. sem_post() 함수는 V 연산을 수행하여 카운터 값을 증가시킨다. sem_getvalue() 함수는 세마포의 현재 카운터 값을 반환한다"
"카운터 세마포는 자원의 인스턴스가 n개일 때(n>1) 사용되며, 이진 세마포는 자원이 1개 있는 경우에 사용되며, 멀티스레드 사이의 자원 관리를 위해 1개의 자원에 대해 1개의 스레드만 액세스할 수 있도록 보호한다 이는 뮤텍스와 매우 유사한 구조를 가진다"
"이진 세마포의 구성 요소는 세마포 변수 S(0과 1 중 하나를 가지는 전역 변수로, S는 1로 초기화됨)와, 대기 큐(사용 가능한 자원이 생길 때까지 스레드들이 대기하는 큐이며, 스레드 스케줄링 알고리즘이 필요함), 2개의 원자 연산인 wait 연산(P 연산으로도 부르며, S를 1 감소시키고, 0보다 작으면 대기 큐에서 잠들며, 0보다 크거나 같으면 자원을 사용하는 코드를 실행)과 signal 연산(V 연산으로 부르며, S를 1 증가시키고, 0보다 크면 그냥 반환하며, 0보다 작거나 같으면 대기 큐에 있는 스레드 중 하나를 깨움)으로 이루어진다"
"동기화 이슈 중 우선순위 역전은 스레드의 동기화로 인해 높은 순위의 스레드가 낮은 스레드보다 늦게 스케줄링되는 현상으로,  우선순위를 기반으로 스케줄링하는 실시간 시스템에서 스레드 동기화로 인해 발생한다"
"우선 순위 역전은 실시간 시스템의 근본 붕괴를 초래할 수 있는데, 우선순위가 높은 스레드가 늦게 실행되면 심각한 문제가 발생할 수 있으며, 또한 낮은 순위의 스레드가 길어지면 더욱 심각한 문제가 발생할 수 있다"
"우선순위 역전을 해결하는 두 가지 방법은 우선순위 올림(priority ceiling)과 우선순위 상속(priority inheritance)이 있는데, 우선순위 올림은 스레드가 공유 자원을 소유할 때 해당 스레드의 우선순위를 미리 정해진 높은 우선순위로 일시적으로 올려서 선점되지 않고 빨리 실행되도록 유도하는 방법이며, 우선순위 상속은 낮은 순위의 스레드가 공유 자원을 가지고 있는 동안 높은 순위의 스레드가 공유 자원을 요청하면 공유 자원을 가진 스레드의 우선순위를 요청한 스레드보다 높게 설정하여 빨리 실행시키는 방법이다"
생산자 소비자 문제는 공유버퍼를 사이에 두고 데이터를 생산하는 생산자들과 해당 데이터를 소비하는 소비자들을 동기화하여 공유버퍼를 문제 없이 사용할 수 있도록 하는 멀티스레딩 응용프로그램에서 자주 발생하는 문제이다
"생산자 소비자 문제의 해결책으로는 뮤텍스나 세마포를 사용하여 상호 배제를 해결하고, 또한 비어 있는 공유 버퍼 문제와 꽉 찬 공유버퍼 문제를 처리할 수 있는 방법이 필요하다"
비어 있는 버퍼 문제를 해결하기 위해 세마포 R을 활용하여 버퍼가 비어 있는지를 살피는 P/V 연산을 사용한다
"버퍼가 비어있는 상태에서 소비자가 읽으려고 할 때, 소비자는 버퍼에서 읽기 전 P 연산을 실행하고 버퍼가 빈 경우(R=0) 소비자가 잠을 자면서 대기하도록 작성한다"
"빈 퍼버에 생산자가 쓸 때, 생산자는 버퍼에 데이터를 기록하고 V 연산을 실행하고 V 연산으로 세마포 변수 R을 1 증가(R=1)하고 대기 중인 소비자를 깨우도록 작성하고 소비자는 깨어나면 P 연산을 마치고 공유버퍼에서 읽어 P 연산으로 세마포 R을 1 감소한다"
꽉 찬 공유 버퍼 문제를 해결하기 위해 세마포 W를 활용하여 버퍼가 꽉 차 있는지를 살피는 P/V 연산을 사용합니다
"공유 버퍼가 찬 상태에서 생산자가 쓰려고 할 때 생산자는 버퍼에 쓰기 전 P 연산을 실행하고 버퍼가 꽉 찬 상태(W=0)이면, 생산자가 잠을 자면서 대기하도록 작성한다"
"버퍼에 데이터가 있는 경우 소비자가 읽을 때, 소비자는 버퍼에서 데이터를 읽은 후 V 연산을 실행하고 V 연산으로 세마포 변수 W를 1 증가시키고(W=1), 대기 중인 생산자를 깨우도록 작성하며 생산자는 깨어나면 P 연산을 마치고 공유 버퍼에 쓰고 P 연산에서 세마포 W를 1 감소(W=0)시킨다."
"
교착상태(deadlock)란 공유자원을 소유한 스레드들 사이에서, 각 스레드는 다른 스레드가 소유한 자원을 요청하여 무한정 대기하고 있는 현상이다"
"교착상태는 사용자가 작성한 멀티스레드 응용프로그램에서 주로 발생하고, 커널 내에서도 발생하지만 거의 발생하지 않는다"
"교착상태는 2개의 스레드가 각각 락을 소유하고 상대가 가진 락을 요청하고 기다릴 때 발생하고, 단일, 다중 CPU 모두에서 발생하고 두 스레드가 서로 다른 CPU에서 실행될 때도 발생한다"
락과 자원에 대한 경쟁이 있는 한 교착상태는 언제든 발생 가능하다
교착상태는 멀티스레드가 자원을 동시에 사용하려는 충돌이나 한 스레드가 여러 자원을 동시에 필요로 하는 상황이나 한 번에 하나씩 자원을 할당하는 운영체제 정책과 할당된 자원은 스레드가 자발적으로 내놓기 전에 강제로 뺏지 못하는 것이 유발 요인이 된다
운영체제는 스레드가 가진 자원을 강제로 뺏지 못하고 만약 강제로 빼앗을 수 있다면 교착상태가 발생하지 않게 할 수 있다
"자원 할당 그래프(RAG)는 자원에 대한 시스템의 상태를 나타내는 방향성 그래프로, 자원 할당 그래프를 통해 교착상태를 판단할 수 있다"
"자원 할당 그래프는 꼭지점, 스레드, 자원, 간선으로 이루어져있는데, 간선은 소유/요청 관계인 자원에서 스레드로 향하는 화살표로 할당 받은 상태를 표시하는 할당 간선과 스레드에서 자원으로 향하는 화살표로 요청을 표시하는 요청 간선으로 이루어져 있다"
교착상태가 발생하는 4가지 필요충분 조건을 코프만 조건이라고 한다
코프만 조건 중 각 자원은 한 번에 하나의 스레드에게만 할당하기 때문에 자원이 한 스레드에게 할당되면 다른 스레드에게는 할당될 수 없는 상호 배제(Mutual Exclusion) 상황일 때 언제든 교착상태가 발생 가능하다
코프만 조건 중 하나는 스레드가 한 자원을 소유(lock)하면서 다른 자원을 기다리는 상황일 때 교착상태가 발생한다
코프만 조건 중 스레드에가 할당된 자원을 강제로 빼앗지 못하는 강제 자원 반환 불가(No Preemption) 상황이 있다
"코프만 조건 중 한 그룹의 스레드들에 대해, 각 스레드는 다른 스레드가 요청하는 자원을 소유하는 환형 고리를 형성하는 환형 대기(Circular Wait) 상황이 있다"
코프만 조건의 4가지 조건 중 하나라도 성립되지 않으면 교착상태가 발생하지 않는다
"교착상태를 해결하는 방법으로 교착상태 예방, 교착상태 회피, 교착상태 감지 및 복구, 교착상태 무시 방법이 있다"
"교착상태 예방은 교착상태 발생 여지를 차단하여 예방하는 것인데, 코프만의 4가지 조건 중 최소 하나를 성립하지 못하게 한다"
"코프만 조건의 4가지 조건 중 하나인 상호 배제 조건은 동시에 2개 이상의 스레드가 자원을 활용할 수 있도록 하여 상호 배제를 없애서 교착상태를 예방할 수 있지만, 컴퓨터 시스템에서 근본적으로 적용이 불가능한 방법이다"
"코프만 조건의 4가지 조건 중 하나인 소유하면서 대기(Hold & Wait) 조건은 운영체제가 스레드 실행 전 필요한 모든 자원을 파악하고 실행 시 한 번에 할당하거나 스레드가 새로운 자원을 요청하려면, 현재 할당 받은 모든 자원을 반환하고, 한 번에 요청하여 할당함으로서 교착상태를 예방할 수 있지만 당장 사용하지 않는 자원을 스레드에게 묶어 두기 때문에 자원 활용률이 떨어지고 다른 스레드는 필요한 자원을 할당 받지 못하고 실행을 대기하게 된다. 이 방법은 모두 가능하지 않거나 비효율적이다"
"코프만 조건의 4가지 조건 중 하나인 강제 자원 반환 불가(No Pre-emption) 조건은 선점을 허용하는 방법으로 교착상태를 예방할 수 있지만, 자원을 강제로 반환하게 된 스레드가 자원을 다시 사용하게 될 때 이전 상태로 되돌아갈 수 있도록 상태를 관리할 필요가 있으며 간단하지 않고 오버헤드가 매우 큰 단점이 있다"
"코프만 조건의 4가지 조건 중 하나인 환형 대기(Circular Wait) 조건은 모든 자원에게 번호를 매기고, 번호순으로 자원을 할당 받게하여 환형 대기를 제거하여 교착상태를 예방할 수 있다"
"교착상태 회피는 자원 할당 시, 미래에 환형 대기가 발생할 것으로 판단되면 자원 할당 하지 않는 정책이다"
"교착상태 회피는 자원의 총수와 현재 할당된 자원의 수를 기준으로 시스템을 안정 상태와 불안정 상태로 나누고 시스템이 안정 상태를 유지하도록 자원을 할당하고, 할당된 자원이 적으면 안정 상태가 크고, 할당된 자원이 늘어날수록 불안정 상태가 커진다"
"교착상태 회피의 문제점은 프로세스가 자신이 사용할 모든 자원을 미리 선언해야하고, 시스템의 전체 자원 수가 고정적이어야 하며, 자원이 낭비된다는 문제점이 있다"
"교착상태를 감지하는 프로그램을 통해 형성된 교착상태를 풀고, 교착상태를 감지하였을 때 복구 방법은 자원 강제 선점이나 롤백, 스레드 강제 종료 방법이 있다"
"자원 강제 선점은 교착상태에 빠진 스레드 중 하나의 자원을 강제로 빼앗아 다른 스레드에게 할당하는 것이고, 롤백은 운영체제는 주기적으로 교착상태가 발생할 것으로 예측되는 스레드의 상태를 저장하여 두고 교착상태가 발생하면 마지막으로 저장된 상태로 돌아가도록 하고, 다시 시작하면서 자원을 다르게 할당하는 것이고 스레드 강제 종료는 교착상태에 빠진 스레드 중 하나 강제 종료하는 것이다"
"교착상태는 반드시 발생하지만 발생 가능성이 극히 적고, 오히려 교착상태를 피하기 위한 비용이 많이 들어가기 때문에 타조 알고리즘과 같은 교착상태 무시 방법도 있다"
"교착상태를 다루는 현실적인 방안으로, 대부분의 운영체제는 ostrich 알고리즘을 사용하여 교착상태가 일어나지 않을 것으로 가정하고, 교착상태에 대한 아무 대책을 세우지 않는 것으로 교착상태가 발생하면 시스템 재시작 혹은 특정 프로세스,스레드를 강제 종료하는 방법이 있고 이는 관련된 데이터를 잃어버릴 수 있지만 큰 손실은 아니다"
""
"
메모리는 컴퓨터 시스템 여러 곳에 계층적으로 존재하며, CPU 레지스터, CPU 캐시, 메인 메모리, 보조기억장치로 계층 구조가 있다"
CPU 레지스터에서 보조기억장치로 갈수록 용량이 증가하고 가격이 저렴해지며 속도가 저하된다
"CPU 레지스터는 몇 개의 명령과 데이터를 저장하는 용도로 바이트 단위, 1KB 미만의 용량을 가지고 있다"
L1/L2 캐시는 한 코어에서 실행되는 명령과 데이터를 저장하고 KB 단위로 SRAM 타입이며 속도는 5ns 정도이다
"L3 캐시는 멀티 코어들에 의해 공유되고 명령과 데이터를 저장하며 MB 단위로 SRAM 타입, 속도는 5ns 정도이다"
"메인 메모리는 실행 중인 전체 프로세스들의 코드와 데이터, 입출력 중인 파일 블록들을 저장하고 GB 단위이며 DRAM 타입으로, 속도는 50ns 정도이다"
"보조 기억장치는 파일이나 데이터베이스, 그리고 메모리에 적재된 프로세스의 코드와 데이터의 일시 저장 장소로 TB 단위이며 마그네틱 필드나 플래시 메모리 타입으로 속도는 20ms 정도이고 가격이 저렴하지만 비휘발성이다"
"CPU의 성능 향상으로 더 빠른 메모리를 요구하게 되고 작지만 빠른 off-chip 캐시가 등장하며 더 빠른 액세스를 위해 on-chip 캐시가 등장하였고, 결국 현재의 멀티 코어의 성능에 적합한 L1,L2,L3 캐시가 등장하게 되었다"
SSD는 컴퓨터의 성능이 향상하면서 처리할 데이터도 많아져 저장 장치의 대형화가 진행되며 빠른 저장 장치를 요구하게 되면서 등장했다
메모리 계층화의 목적은 빠른 프로그램 실행을 인한 CPU의 메모리 액세스 시간을 줄이기 위함이다
"캐시 미스란 컨텍스트 스위칭으로 인해 새로 실행되는 스레드의 경우 스레드의 명령, 데이터를 캐시에서 찾을 수 없는 것이다"
"메모리 계층화가 성공한 이유는 참조의 지역성 덕분에 CPU가 캐시 메모리에 적재된 코드와 데이터를 반복적으로 사용하여, 캐시를 채우는 시간의 손해보다 빠른 캐시를 이용하는 이득이 크기 때문이다"
"운영체제에 의한 메모리 관리가 필요한 이유는 메모리가 공유 자원으로서 프로세스 생성과 종료 시 메모리 할당 및 반납을 관리하고, 메모리 보호를 통해 프로세스의 독립된 공간과 커널 공간을 보호하며, 가상 메모리를 통해 물리 메모리의 한계를 극복하고, 메모리 효율성을 높여 더 많은 프로세스를 실행함으로써 전체 시스템의 처리율을 향상시키기 때문이다"
메모리는 오로지 주소로만 접근이 가능하고 물리 주소와 논리/가상 주소로 나뉘어져있다
"물리 주소(physical address)는 물리 메모리(RAM)에 매겨진, 하드웨어에 의해 고정된 연속적인 주소 체계로, 0에서 시작하며, 시스템 주소 버스를 통해 물리 주소의 신호를 받는다"
"논리/가상 주소(logical address/virtual address)는 개발자나 프로세스가 프로세스 내에서 사용하는 주소로, 0에서 시작하여 연속되는 주소 체계를 가지며, CPU가 프로세스를 실행하는 동안 다루는 모든 주소는 논리 주소이고, 이는 프로세스 내에서 매겨진 상대 주소로서 프로그램의 변수나 코드에 대한 주소이며, 컴파일러와 링커에 의해 매겨져 실행 파일 내 이진 프로그램의 주소로 사용되지만, 사용자나 프로세스는 물리 주소를 직접 알 수 없다"
"MMU(Memory Management Unit)는 논리 주소를 물리 주소로 변환하는 하드웨어 장치로, CPU가 생성한 논리 주소를 물리 주소로 변환하여 메모리에 접근하게 하며, 오늘날 MMU는 인텔이나 AMD의 x86 CPU에서처럼 CPU에 내장되어 여러 프로세스가 하나의 물리 메모리에서 실행될 수 있도록 한다"
"프로세스의 모든 코드는 논리 주소로 구성되어 있으며, CPU가 읽고 해석하고 생성하는 모든 주소는 논리 주소로, 논리 주소와 물리 주소 간의 매핑 테이블을 통해 MMU를 거쳐 논리 주소가 물리 주소로 변환되어 출력되며, MMU는 이 매핑 테이블을 이용해 주소 변환을 수행한다"
"ASLR(Address Space Layout Randomization)는 2001년경 도입된 해커들의 메모리 공격에 대한 대비책으로, 대부분의 운영체제가 활용하며, 프로세스의 주소 공간 내 스택, 힙, 라이브러리 영역을 실행할 때마다 랜덤 배치하여 논리 주소를 변경하는 기법으로, 코드나 전역 변수가 적재되는 데이터 영역의 논리 주소는 변하지 않는다"
"메모리 할당은 운영체제가 새 프로세스를 실행시키거나 실행 중인 프로세스가 메모리를 필요로 할 때 물리 메모리를 할당하여, 프로세스의 코드(함수), 변수, 스택, 동적 할당 공간 등에 접근하여 실행이 할당된 물리 메모리에서 이루어지도록 하는 것이다"
메모리 할당 기법에는 연속 메모리 할당과 분할 메모리 할당으로 나눌 수 있다
"연속 메모리 할당은 프로세스별로 연속된 한 덩어리의 메모리를 할당하는 방식으로, 고정 크기 할당은 메모리를 고정 크기의 파티션으로 나누어 프로세스당 하나의 파티션을 할당하며, 가변 크기 할당은 메모리를 가변 크기의 파티션으로 나누어 프로세스당 하나의 파티션을 할당하는 방식입니다"
"분할 메모리 할당은 프로세스에게 여러 덩어리의 메모리를 할당하는 방식으로, 고정 크기 할당은 고정 크기의 동일한 덩어리 메모리를 분산하여 할당하며, 대표적인 방법은 세그먼테이션(segmentation) 기법을 사용합니다. 가변 크기 할당은 가변 크기의 덩어리 메모리를 분산하여 할당하는 방식으로, 대표적인 방법은 페이징(paging) 기법을 사용합니다"
단편화(fragmentation)는 프로세스에게 할당할 수 없는 조각 메모리인 홀(hole)이 생기는 현상이다
"내부 단편화(internal fragmentation)는 할당된 메모리 내에서 프로세스 크기가 파티션보다 작아 사용할 수 없는 홀이 생기는 현상으로, IBM OS/360 MFT(Multiple Programming with a Fixed Number of Tasks) 사례가 있다"
"외부 단편화(external fragmentation)는 가변 크기의 파티션이 할당되고 반환되는 과정에서 메모리 사이에 여러 개의 작은 홀(hole)이 생겨 프로세스 크기보다 작아 할당할 수 없는 현상으로, IBM OS/360 MVT(Multiple Programming with a Variable Number of Tasks) 사례가 있으며 이를 해결하기 위해 메모리 압축(compaction)이 필요하다"
"연속 메모리 할당 구현을 위해 하드웨어는 CPU 레지스터와 논리 주소를 물리 주소로 변환해주는 주소 변환 하드웨어(MMU)가 필요하고, CPU 레지스터에서 base 레지스터는 현재 실행 중인 프로세스의 물리 메모리 시작 주소를, limit 레지스터는 할당된 메모리 크기를, 주소 레지스터는 현재 액세스하는 논리 주소를 저장한다"
"연속 메모리 할당 구현을 위해 운영체제는 모든 프로세스에 대해 프로세스별로 할당된 물리 메모리의 시작 주소와 크기 정보를 저장하고, 비어있는 메모리 영역을 관리하며, 새 프로세스를 스케줄링하여 실행시킬 때마다 물리 메모리의 시작 주소와 크기 정보를 CPU 내부의 base 레지스터와 limit 레지스터에 적재한다"
"연속 메모리 할당의 장점은 논리 주소를 물리 주소로 바꾸는 과정이 단순하고 CPU의 메모리 액세스 속도가 빠르며, 운영체제가 관리해야 할 정보량이 적어 부담이 덜한 반면, 단점으로는 메모리 할당의 유연성이 떨어져 작은 홀들을 합쳐 충분한 크기의 메모리가 있음에도 연속된 메모리를 할당할 수 없는 경우가 발생하여 메모리 압축 기법으로 해결해야 한다"
"운영체제는 가변 할당된 파티션의 위치, 크기, 비어 있는지 유무에 관한 정보를 리스트로 유지 관리한다"
"운영체제의 홀 선택 전략에는 first-fit(최초 적합)으로 홀 리스트를 검색하여 처음 만나는 요청 크기보다 큰 홀을 선택해 할당 속도가 빠르지만 단편화 가능성이 있으며, best-fit(최적 적합)으로 요청 크기를 수용할 수 있는 가장 작은 홀을 선택해 가장 작은 홀이 새로 생성되며, worst-fit(최악 적합)으로 요청 크기를 수용할 수 있는 가장 큰 홀을 선택해 가장 큰 홀이 새로 생성되는 방식이 있다"
"버디(Buddy) 시스템은 가변 크기 할당의 외부 단편화를 줄이기 위해 고정 크기 할당을 함께 사용하여 할당 크기를 정해 놓은 연속 메모리 할당 기법으로, 블록 크기는 최소 블록의 2^n 배로 구성된다"
"세그먼트(segment)는 개발자의 관점에서 보는 프로그램의 논리적 구성 단위로, 세그먼트마다 크기가 다르며 일반적으로 코드 세그먼트, 데이터 세그먼트, 스택 세그먼트, 힙 세그먼트로 구성된다"
"세그먼테이션 기법은 프로세스를 논리 세그먼트 크기로 나누고 각 논리 세그먼트를 물리 메모리(물리 세그먼트)에 할당하여 관리하는 메모리 관리 기법으로, 프로세스의 주소 공간을 여러 개의 논리 세그먼트로 나누고 이를 물리 세그먼트에 매핑하며, 이 과정은 컴파일러, 링커, 로더, 운영체제에 의해 이루어지고, 시스템 전체 세그먼트 매핑 테이블을 사용해 논리 주소를 물리 주소로 변환하지만 외부 단편화가 발생할 수 있다"
"세그먼테이션의 구현에는 하드웨어 지원이 필요하며, 논리 주소는 [세그먼트 번호, 옵셋]으로 구성되고, 옵셋은 세그먼트 내 상대 주소를 나타내며, CPU는 세그먼트 테이블의 시작 주소를 가리키는 레지스터(segment table base register)가 필요하고, MMU 장치는 논리 주소를 물리 주소로 변환하며 논리 주소가 세그먼트 범위를 넘는지 판별하고, 세그먼트 테이블은 메모리에 저장되어 세그먼트별 시작 물리 주소와 세그먼트 크기 정보를 포함한다"
"세그먼테이션 구현을 위해 운영체제는 세그먼트의 동적 할당/반환 및 세그먼트 테이블 관리 기능을 구현하여, 프로세스의 생성과 소멸에 따라 세그먼트를 동적으로 할당 및 반환하고, 물리 메모리에 할당된 세그먼트 테이블과 자유 공간에 대한 자료를 유지하며, 컨텍스트 스위칭 시 CPU의 레지스터에 적절한 값을 로딩하는 기능을 포함한다"
"세그먼테이션 구현을 위해 컴파일러, 링커, 로더는 사용자 프로그램을 세그먼트 기반으로 컴파일, 링킹, 로딩을 지원한다"
"세그먼트들의 크기가 같지 않아 세그먼트 사이에 작은 크기의 홀이 발생하여 외부 단편화가 발생하지만, 내부 단편화는 발생하지 않는다"
""
"
프로세스의 주소 공간과 물리 메모리를 동일한 크기의 페이지와 프레임으로 나누어 각각에 번호를 붙이고, 페이지 테이블을 통해 페이지 번호와 프레임 번호를 1:1로 매핑한다"
"페이징 기법은 프로세스의 주소 공간과 물리 메모리를 페이지 단위로 분할하여 각 페이지를 물리 메모리의 프레임에 분산 할당하고, 페이지 테이블을 통해 논리 주소를 물리 주소로 변환하는 방식으로 내부 단편화가 발생하지만 세그먼테이션보다 우수한 메모리 관리 기법이다"
"페이징의 우수성은 메모리를 고정 크기로 분할하여 쉽게 구현할 수 있고, CPU에 의존하지 않아 다양한 시스템에 이식 가능하며, 시스템에 따라 페이지 크기를 조정할 수 있어 메모리 활용과 시간 오버헤드가 우수하고, 외부 단편화가 없다는 점에 있다"
"32비트 CPU 컴퓨터에서 4GB 주소 공간과 4KB 페이지 크기를 가지는 프로세스는 코드, 데이터, 힙, 스택으로 구성된 6개의 페이지를 사용하며, 페이지 테이블은 모든 페이지를 나타내지만 현재 6개의 항목만 사용된다"
"하나의 예시로, 동적 할당 요청 시, 프로세스는 200바이트 할당을 위해 논리 페이지 5와 물리 프레임 2를 할당받아 논리 주소 20480번지를 물리 주소 8192번지로 변환하여 사용하고, 반환 시 페이지 5와 프레임 2가 모두 반환된다"
프로세스가 시스템 호출을 실행하면 커널 공간의 논리 주소 페이지 k가 현재 프로세스의 페이지 테이블을 통해 물리 프레임으로 변환되어 커널 코드가 실행된다
"32비트 CPU에서, 페이지 크기가 4KB인 경우 물리 메모리의 최대 크기는 4GB이고 주소 공간의 크기는 물리 메모리 크기에 상관없이 4GB, 한 프로세스는 최대 약 100만개의 페이지로 구성되며 페이지 테이블의 크기는 32비트라면 4MB이다"
"응용프로그램이 하나의 프로세스라고 할 때, 응용프로그램의 최대 크기, 즉 개발자가 작성할 수 있는 프로그램의 최대 크기는 운영체제가 설정한 사용자 공간의 크기와 동일하다"
"페이징에서는 외부 단편화는 없으나 내부 단편화가 발생하며, 이는 주로 프로세스의 마지막 페이지에서 발생하고 평균 단편화 크기는 페이지 크기의 절반이다"
"32비트 CPU에서, 페이지 크기가 2KB, 현재 설치된 메모리 1GB, 프로세스 A는 사용자 공간에서 54321바이트를 차지한다고 할 때 물리 메모리의 프레임 크기는 2KB로 페이지 크기와 동일하고 물리 메모리의 프레임 개수는 물리 메모리를 프레임 크기로 나누면 약 50만개, 프로세스의 주소 공간 크기와 페이지의 개수는 4GB와 2백만개, 프로세스 A는 몇 개의 페이지로 구성되어 있고, 프로세스 A를 모두 적재하기 위한 물리 프레임의 개수는 27개 프레임, 물리 프레임 역시 27개가 필요하다. 페이지 테이블 항목의 크기가 4바이트 일 때, 프로세스 A의 페이지 테이블의 크기는 8MB이다"
"페이징의 논리 주소는 32비트 논리 주소 체계에서, 상위 20비트의 페이지 번호와 하위 12비트의 옵셋으로 구성된다"
"페이징 구현을 위해 CPU는 페이지 테이블 주소를 가진 PTBR 레지스터와 MMU 장치가 논리 주소를 물리 주소로 변환하고 메모리 보호를 담당하며, 운영체제는 프레임의 동적 할당/반환과 페이지 테이블 관리, 프로세스 생성/소멸 시 프레임 관리, 그리고 컨텍스트 스위칭 시 CPU 레지스터 로딩을 지원한다"
"페이지 테이블의 문제점은 메모리 액세스를 위해 두 번의 물리 메모리 액세스가 필요해 실행 속도가 저하되는 문제를 TLB로 해결하고, 프로세스의 실제 크기가 작아 대부분의 페이지 테이블 항목이 비어 있어 메모리가 낭비되는 문제를 2레벨 페이지 테이블 등으로 해결한다는 점이다"
"TLB(Translation Look-aside Buffer)를 통해 2번의 물리 메모리 액세스 문제를 해결할 수 있는데, TLB란 주소 변환 캐시로, 최근에 접근한 페이지와 프레임 번호 쌍을 저장하여 논리 주소를 물리 주소로 바꾸는 과정에서 페이지 테이블을 읽어오는 시간을 줄여 실행 속도를 높이며, 현대 컴퓨터에서는 MMU 내에 위치하고, content-addressable memory 또는 associative memory로 불리며, 고가이지만 크기가 작아 64~1024개의 항목 정도를 저장할 수 있다"
"TLB를 활용한 메모리 액세스 과정에서 CPU로부터 발생한 논리 주소의 페이지 번호가 TLB로 전달되면, 페이지 번호와 TLB 내 모든 항목을 동시에 비교하여 TLB에 페이지가 있으면 TLB hit로 프레임 번호와 offset 값으로 물리 주소를 완성하고, TLB에 페이지가 없으면 TLB miss로 MMU가 페이지 테이블에서 프레임 번호를 읽어와 물리 주소를 완성하며, miss한 페이지의 [페이지번호, 프레임번호] 항목을 TLB에 삽입한다"
"TLB는 참조의 지역성 덕분에 순차 메모리 액세스 시 실행 속도가 빠르지만, 랜덤 액세스나 반복이 없는 경우 TLB 미스가 자주 발생해 속도가 느려지며, 성능을 높이기 위해 TLB 항목을 늘리면 비용이 증가하고, 페이지 크기가 클수록 TLB 히트율이 증가해 실행 성능이 향상되지만 내부 단편화로 인한 메모리 낭비가 발생하여 이 둘 사이에 trade-off가 존재한다. 
TLB reach는 TLB가 가득 찼을 때 미스 없이 작동할 수 있는 메모리 액세스 범위로, TLB 항목 수와 페이지 크기의 곱으로 계산된다"
"TLB를 고려한 컨텍스트 스위칭 과정은 CPU의 모든 레지스터를 PCB에 저장하고, PCB에 있는 프로세스의 페이지 테이블 주소를 MMU의 PTBR에 적재하여 TLB 미스 시 페이지 테이블을 액세스할 수 있게 한 후, 이전 프로세스의 매핑 정보로 인한 오류를 방지하기 위해 TLB 내용을 모두 지우고, 새 프로세스의 실행이 시작되면서 TLB가 다시 채워지도록 하며, 마지막으로 새 프로세스의 컨텍스트를 PCB에서 CPU에 적재하는 방식으로 진행된다"
"32비트 CPU 환경에서 프로세스당 페이지 테이블은 약 100만 개의 페이지 항목으로 구성되어 4MB의 메모리를 차지하지만, 실제로 10MB의 메모리를 사용하는 프로세스는 2560개의 항목만 필요하여 실제 활용되는 페이지 테이블 비율이 0.0024로 매우 낮아 메모리 낭비가 발생한다"
페이지 테이블 낭비 문제의 해결책으로 역 페이지 테이블과 멀티 레벨 페이지 테이블이 있다
"역 페이지 테이블(IPT)은 물리 메모리 전체 프레임에 대해 각 프레임이 어떤 프로세스의 어떤 페이지에 할당되었는지를 나타내는 테이블로, 시스템에 하나만 존재하며 항목 수는 물리 메모리의 프레임 개수와 같으며, 각 항목은 [프로세스번호(pid), 페이지 번호(p)]로 구성된다. 
역 페이지 테이블의 논리 주소는 [프로세스번호, 페이지 번호, 옵셋] 형식으로, 주소 변환 시 논리 주소에서 (프로세스번호, 페이지 번호)로 역 페이지 테이블을 검색해 일치하는 항목의 번호를 프레임 번호로 사용하고, 프레임 번호와 옵셋을 연결해 물리 주소를 생성한다"
"멀티 레벨 페이지 테이블은 전체 페이지 테이블을 페이지 크기로 분할하고, 각 분할된 페이지 테이블을 가리키도록 페이지 디렉터리를 구성하여 사용 중인 페이지들에 대해서만 페이지 테이블을 구성하는 방식이다"
"역 페이지 테이블은 시스템에 하나 존재하며, 항목 크기는 프로세스 번호와 페이지 번호가 각각 4바이트일 때 8바이트가 되며, 항목 수는 물리 메모리 크기를 프레임 크기로 나눈 값으로, 예를 들어 물리 메모리가 4GB이고 프레임 크기가 4KB일 때 약 100만 개의 항목이 필요해 8MB의 테이블 크기를 가지게 되며, 이는 물리 메모리 크기에 따라 달라진다. 기존 페이지 테이블과 비교하면, 10개의 프로세스가 실행 중일 때 기존 페이지 테이블의 총 크기는 40MB(4MB x 10개)인 반면, 역 페이지 테이블은 8MB로 기존 방식보다 1/5 수준의 메모리만 필요하다"
역 페이지 테이블의 구현 방법 중 선형 역 페이지 테이블은 주소 변환 시 역 페이지 테이블의 모든 항목을 처음부터 하나씩 비교하기 때문에 시간이 많이 걸리는 단점이 있다
"역 페이지 테이블의 구현 방법 중 해시 역 페이지 테이블 방식은 해시 함수를 이용하여 'PID, p'를 키로 해싱하여 한번의 해시 함수 연산으로 프레임 주소를 알 수 있으며, 이 방식은 PowerPC와 UltraSPARC CPU에서 사용된다"
"멀티레벨 페이지 테이블은 현재 사용 중인 페이지들에 대해서만 페이지 테이블을 만들어 메모리 낭비를 줄이며, 페이지 테이블을 수십에서 수백 개의 작은 페이지 테이블로 나누어 여러 레벨로 구성하는 방식이다"
"2-레벨 페이지 테이블의 경우 논리 주소는 [페이지 디렉터리 인덱스, 페이지 테이블 인덱스, 옵셋] 형식으로 구성되며, 페이지 크기가 4KB일 때 하위 12비트는 페이지 내 옵셋 주소를, 상위 20비트는 페이지 디렉터리 인덱스와 페이지 테이블 인덱스를 나타낸다"
"2-레벨 페이지 테이블은 논리 주소를 페이지 번호와 옵셋으로 구성하고, 페이지 번호 부분을 2개의 레벨로 나누어 페이지 디렉터리와 페이지 테이블의 트리 구조를 형성하며, 사용 중인 페이지들에 대해서만 페이지 테이블을 할당하는 방식이다"
"2-레벨 페이지 테이블은 논리 주소의 페이지 번호를 페이지 디렉터리 인덱스와 페이지 테이블 인덱스로 나누어 트리 구조를 형성하고, 사용 중인 페이지들에 대해서만 해당 페이지 테이블을 할당하여 효율적으로 메모리를 관리하는 방식으로 형성된다"
"2-레벨 페이지 테이블은 최대 메모리 소모량이 1개의 페이지 디렉터리(4KB)와 최대 1024개의 페이지 테이블(4MB)로 4.004MB가 되지만, 일반적으로 프로세스는 모든 페이지 테이블을 사용하지 않으며, 예를 들어 프로세스가 1000개의 페이지로 구성된 경우 1개의 페이지 테이블로 매핑되어 8KB만 소모하고, 프로세스가 400MB 크기인 경우 100개의 페이지 테이블이 필요하여 404KB를 소모한다"
"기존 페이지 테이블의 경우 프로세스 크기에 관계없이 4MB가 소모되지만, 2-레벨 페이지 테이블은 페이지 테이블로 인한 메모리 소모를 현저히 줄일 수 있다"
""
가상 메모리 기법의 핵심은 물리 메모리를 디스크 공간으로 확장
"스와핑(swapping), 메모리가 부족할 때, 실행에 필요하지 않는 부분은 하드 디스크로 이동"
"가상 메모리 개념 : 운영체제는 물리 메모리 영역을 하드 디스크까지 연장, 프로세스를 물리 메모리와 하드 디스크에 나누어 저장, 물리 메모리 한계 극복"
가상 메모리 개념 : 프로세스의 실행 시 프로세스 전체가 물리 메모리에 적재되어 있을 필요 없음
"가상 메모리 개념 : 운영체제는 물리 메모리의 빈 영역이 부족하게 되면, 물리 메모리 일부분을 하드 디스크로 옮겨 물리 메모리의 빈 영역 확보"
가상 메모리 개념 : 물리 메모리를 확장하여 사용하는 디스크 영역을 스왑 영역이라고 부름
대표적인 가상 메모리 구현 방법 : 요구 페이징
"요구 페이징이란 페이징 기법을 토대로 프로세스의 일부 페이지들만 메모리에 할당하고, 페이 지가 필요할 때 메모리를 할당받고 페이지를 적재시키기는 메모리 관리 기법"
"요구 페이징 개념 : 현재 실행에 필요한 일부 페이지만 메모리에 적재하고 나머지는 하드 디스크에 두고, 페이지가 필요할 때 메모리에 적재하는 방 식"
"요구 페이징 구현 : 운영체제는 첫 페이지만 물리 메모리에 적재하고, 실행 중 다음 페이지가 필요하면 그때 적재 시키는 방법 사용"
"스왑 영역 : 메모리가 부족할 때, 메모리를 비우고 페이지를 저장해두는 하드 디스크의 영역"
"페이지 폴트 : CPU가 액세스하려는 페이지가 물리 메모리에 없을 때, 페이지 폴트 발생"
스왑-인(swap-in) – page-in : 스왑 영역에서 페이지를 프레임으로 읽어들이는(복사) 행위
스왑-아웃(swap-out) - page-out : 프레임에 저장된 페이지를 스왑 영역에 저장하는 행위
"페이지 폴트 : 요구 페이징에서 가장 중요한 상황,  CPU가 발생시킨 가상 주소의 페이지가 메모리 프레임에 없는 상황, MMU가 가상 주소를 물리 주소로 바뀌는 과정에서 발생
프로세스의 생성 : 부모 프로세스의 fork() 사스템 호출로 생성, 프로세스의 생성은 메모리 할당과 페이지의 적재에서 시작"
fork()의 자식 프로세스의 메모리 생성하는 방법에는 완전 복사와 쓰기 시 복사가 있다
완전 복사는 부모 프로세스의 메모리를 완전히 복사하여 자식 프로세스 생성
"완점 복사는 비효율적인데 그 이유는 많은 응용프로그램들이, fork() 후 생성된 자식프로세스가 execlp()를 호출 하여 곧 바로 다른 프로그램을 실행하도록 작성되기 때문"
"쓰기 시 복사의 장점은 프로세스 생성 시간 절약, 메모리 절약이 있다"
페이지 폴트가 발생하면 필연적으로 디스크 I/O 증가
스래싱이란 페이지 폴트가 계속 발생하여 메모리 프레임에 페이지가 반복적으로 교체되고 디스크 입출력이 심각하게 증가하는 현상
"스래싱의 원인은 다중프로그래밍의 정도가 과도한 경우, 잘못된 메모리 할당/페이지 교체 알고리즘, 기본적으로 메모리량이 적을 때 발생"
"스레싱 해결 및 예방 방법에는 다중프로그래밍 정도 줄이기, 하드 디스크 대신 빠른 SSD 사용, 메모리 늘리기가 있다"
참조의 지역성은 CPU가 짧은 시간 범위 내에 일정 구간의 메모리 영역을 반복적으로 참조하는 경향
"대표적인 참조의 지역성 형태는 시간 지역성, 공간 지역성이 있다"
작업 집합이란 일정 시간 범위 내에 프로세스가 액세스한 페이지들의 집합이다
"요구 페이지의 성능에 영향을 미치는 필수 알고리즘에는 프레임 할당 알고리즘, 페이지 교체 알고리즘이 있다"
프레임 할당의 목표는 프로세스에게 작업 집합에 포함된 페이지들을 적재할 충분한 메모리 할당이다
프레임 할당의 방법에는 균등 할당과 비례 할당이 있다
프로세스에게 할당할 적정 프레임의 개수는 작업 집합을 약간 넘나드는 크기이다
페이지 교체란 메모리 프레임 중 하나를 선택하여 비우고 이곳에 요청된 페이지를 적재하는 과정이다
페이지 교체 알고리즘의 목표는 현재 작업 집합에 포함되지 않거나 가까운 미래에 참조되지 않을 페이지를 희생 페이지로 선택이다
지역 교체란 요청한 프로세스에게 할당된 프레임 중에서 희생 프레임을 선택하는 것을 의미한다
"지역 교체의 장점으로는 한 프로세스에서 발생한 스래싱이 다른 프로세스로 전파되지 않음, 프로세스 별로 독립적으로 페이지 폴트 처리이 있다"
전역 교체란 전체 메모리 프레임 중에서 선택하는 방법이다
"페이지 교체 알고리즘의 종류로는 FIFO, LRU, Clock가 있다"
LRU알고리즘은 가장 최근에 사용되지 않는 페이지 선택하는 알고리즘이다.
"운영체제는 파일 생성, 기록, 읽기 모든 과정 통제"
"플래터란 정보가 저장되는 매체, 원형 판"
헤드는 플래터에서 정보를 읽고 저장하는 장치
디스크 장치는 디스크 물리 주소 사용
운영체제는 논리 블록 주소 사용
응용프로그램은 파일 내 바이트 주소 사용
파일 주소 변환하는 과정은 운영체제는 파일 내 바이트 주소를 논리 블록 주소로 변환하고 디스크 장치는 논리 블록 주소를 CHS 물리 주소로 변환한다
파일 시스템이란 저장 매체에 파일을 생성하고 저장하고 읽고 쓰는 운영체제의 기능을 통칭
트리 계층 구조로 파일 시스템 구성
디렉토리는 논리적인 관점에서는 여러 파일 혹은 서브 디렉토리를 포함하는 컨테이너
"디렉토리는 물리적인 관점에서는 파일이나 서브디엑토리의 이름, 이들에 관한 위치 정보, 혹은 속성 등을 저장하는 특별한 파일이다"
"파일 시스템 메타 정보란 파일 시스템 전체 크기와 현재 사용 크기, 저장 장치에 구축된 파일 시스템의 비어 있는 크기, 저장 장치에 있는 블록들의 리스트가 들어 있다"
"파일 메타 정보에는 파일 이름, 파일 크기, 파일이 만들어진 시간,  파일이 수정된 시간,  파일이 가장 최근에 액세스된 시간, 파일을 만든 사용자, 파일 속성(접근 권한), 파일이 저장된 위치가 들어 있다"
"파일 시스템 종류로는 FAT, NTFS, YFS, HFS등이 있다"
"FAT 파일 시스템의 구조에는 부트 섹터, FAT1, FAT2, 루트디렉터리, 데이터 블록들이 있다"
"FAT 파일 시스템의 파일 블록 전략은 파일 데이터를 블록 단위로 디스크에 분산 저장, 파일 메타 데이터는 디렉터리에 저장, 저장된 파일 블록들의 위치는 FAT 테이블에 기록"
FAT 테이블에는 파일 시스템에 생성된 모든 파일에 대해 저장된 블록 번호들이 담겨있다
"Unix 파일 시스템 구조에는 부트 블록, 수퍼 블록, i-node와 i-node 리스트, 데이터 블록들이 있다"
"수퍼 블록에는 파일 시스템의 크기와 상태 정보(수퍼 블록의 수정 여부), 파일 시스템 내의 자유 블록 수, 자유 블럭들의 리스트, 자유 블록 리스트에서 요청시 할당할 다음 블록 인덱스, 파일 시스템 내의 inode 리스트의 크기, 파일 시스템 내의 자유 inode 수, 파일 시스템 내의 자유 inode들의 리스트, 파일 시스템 내의 자유 inode 리스트에서 요청시 할당할 다음 자유 inode 인덱스, 파일 시스템의 논리 블록의 크기, 루트 디렉터리의 i-node 번호, 수퍼 블록이 갱신된 최근 시간이 있다"
"I-node에는 파일 타입과 파일 접근 권한, 파일 소유자, 파일 그룹, 파일 크기, 마지막 파일 접근 시각, 마지막 파일 수정 시각, 마지막 i-node 수정 시각, 파일이 저장된 블록들에 대한 인덱스에 대한 정보들이 들어있다"
파일을 찾는 과정은 파일의 경로명으로부터 파일의 i-node를 찾는 과정이다
"파일 열기의 과정은 1. 파일 이름으로 i-node 번호를 알아내기, 2. 디스크 i-node를 커널 메모리의 i-node 테이블에 적재, 3. 오픈 파일 테이블에 새 항복 만들기, 4. 프로세스별 오픈 파일 테이블에 새 항목 만들기, 5. open()은 프로세스별 오픈 파일 테이블 항목 번호 리턴"
"파일 쓰기 과정은 1. write(fd,...)는 fd 번호의 프로세스별 파일 테이블을 참조, 2. 파일 테이블 참조, 3. i-node 참조, 4. 해당 블록이 버퍼 캐시에 있는 지 확인, 5. 사용자 공간의 버퍼에서 버퍼 캐시로 쓰기, 6. 추후 버퍼 캐시가 교체되거나 플러시 될 때, 버퍼 캐시의 내용이 저장 장치에 기록"
"파일 닫기 과정은 1. 프로세스의 오픈 파일 테이블 항목에 기록된 내용 지우기, 2. 프로세스의 오픈 파일 테이블 항목을 지우기 전, 파일 테이블의 항목을 찾고 (지우고) 반환하기, 3. 파일 테이블 항목을 반환하기 전, 이 메모리 i-node의 사용 해제, 4. 버퍼 캐시에 있는 이 파일의 블록들이 수정되었거나 새로 만든 블록인 경우 디스크에 기록."
저장 장치 목적은 프로그램과 데이터를 보조적으로 저장
"저장 장치의 특성은 대용량 장치, 비 휘발성 영구 기억 장치, 가상 메모리의 스왑 공간이다"
입출력 병목이란 저장 장치의 입출력에 과부하가 걸려 있는 상태
입출력 병목은 CPU 유휴 시간을 늘리고 시스템전체를 느리게 함
"입출력 병목을 줄이기 위한 방법으로는 주기억장치 메모리 늘리기, 디스크 캐시 늘리기, 디스크 스케줄링, SSD와 같은 빠른 저장 장치 사용, RAID와 같은 병렬 저장 장치 사용"
"데이터 신뢰성을 높이는 방법으로는 디스크 미러링, RAID가 있다"
"디스크 미러링은 2개의 동일한 디스크 사용, 항상 동일한 데이터가 기록되도록 구현"
RAID란 여러 개의 값싼 디스크를 병렬로 연결하여 사용하는 방법
RAID 레벨 0은 같은 규격의 디스크를 병렬로 연결하여 여러 개의 데이터를 여러 디스크에 동 시에 저장하거나 가져올 수 있음
RAID 레벨 0은 장애가 발생하면 데이터를 잃어 일반적으로 단독으로 사용하지 않음
"RAID 레벨 2는 오류 교정 코드를 따로 관리하고, 오류가 발생하면 이 코드를 이용하여 디스크를 복구"
"RAID 레벨 3는 오류 검출 패리티 이용 방식: 패리티 정보를 담고 있는 별도 디스크 추가된 형태, 패리티 비트를 구성한 후 데이터 디스크가 아닌 별도의 디스크에 보관함으로써 장 애 발생 시 오류를 복구"
RAID 레벨 4란 RAID 3과 유사하나 데이터를 블록 단위로 스트라이핑한다
"RAID 레벨 5는 블록수준 분산 패리티, 패리티 비트를 여러 디스크에 분산하여 보관함으로써 패리티 비트 디스크의 병목 현상을 완화, 패리티 비트를 해당 데이터가 없는 디스크에 보관, 한 디스크에 장애가 발생하면 다른 디스크에 있는 패리티 비트를 이용하여 데이터를 복구할 수 있음"
디스크 장치는 디스크 제어 모듈과 디스크 매체 모듈로 구성
디스크 제어 모듈은 호스트로부터 명령을 받아 디스크 매체 모듈을 제어한다
디스크 매체 모듈은 디스크 헤드를 움직여 물리적인 입출력 시행
"디스크 입출력 명령을 처리하는 과정은 탐색, 회전 지연, 내부 전송, 외부 전송 순이다"
탐색이란 디스크 장치 내 모터를 이용하여 디스크 헤드가 현재 실린더에서 목표 실린더로 이동하는 과정
"회전 지연이란 탐색 후 플래터가 회전하여, 헤드 밑에 목표 섹터가 도달할 때까지 기다리는데 시간"
디스크 전송은 내부 전송과 외부 전송으로 나뉜다
내부 전송 시간은 플래터 표면(디스크 헤드)와 디스크 캐시 사이의 데이터 전송
외부 전송 시간은 디스크 캐시와 호스트 컴퓨터 사이에 데이터가 전송되는 시간
디스크 큐란 도착하는 여러 디스크 입출력 요청을 저장하는 큐이다
"디스크 스케줄링 알고리즘 종류로는 FCFS, SSTF, SCAN, C-SCAN, LOOK, C-LOOK가 있다"
FCFS는 디스크 큐에 도착한 순서대로 요청들을 처리한다
SSTF는 현재 디스크 헤드가 있는 실린더에서 가장 가까운 요청 선택한다
"고수준 포맷팅이란 저수준 포맷된 하드 디스크를 여러 개의 파티션(논리적인 공간)으로 나누고, 각 파티션에 비어있는 파일 시스템을 구축하는 과정이다"
SSD란 메모리 계층 구조의 최하위 단에 위치하는 보조 기억 장치
"플래시 메모리란 SSD 내부의 저장소, SSD 제어기 내 플래시 제어기에 의해 입출력"
DRAM 캐시는 읽고 쓸 데이터의 임시 저장하는 공간
플래시의 블록은 쓰기나 지우기 횟수에 비례하여 닳아(wear)감.
